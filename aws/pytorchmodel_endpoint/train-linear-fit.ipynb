{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "entitled-spiritual",
   "metadata": {},
   "source": [
    "## Creating the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "treated-portal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(100, 1)\n",
    "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n",
    "\n",
    "# Shuffles the indices\n",
    "idx = np.arange(100)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Uses first 80 random indices for train\n",
    "train_idx = idx[:80]\n",
    "# Uses the remaining indices for validation\n",
    "val_idx = idx[80:]\n",
    "\n",
    "\n",
    "# Generates train and validation sets\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-steering",
   "metadata": {},
   "source": [
    "### Formatting the Dataset for Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "authentic-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "charged-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LayerLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "seventh-arrival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[-0.2971]])), ('linear.bias', tensor([0.2363]))])\n",
      "OrderedDict([('linear.weight', tensor([[1.9690]])), ('linear.bias', tensor([1.0235]))])\n"
     ]
    }
   ],
   "source": [
    "# Now we can create a model and send it at once to the device\n",
    "model = LayerLinearRegression().to(device)\n",
    "# We can also inspect its parameters using its state_dict\n",
    "print(model.state_dict())\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # What is this?!?\n",
    "    model.train()\n",
    "\n",
    "    # No more manual prediction!\n",
    "    # yhat = a + b * x_tensor\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    loss = loss_fn(y_train_tensor, yhat)\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "judicial-cycling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.9770], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Testing the prediction \n",
    "a = np.array([1.5])\n",
    "y = model(torch.as_tensor(a,dtype=torch.float32,device=device))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-stamp",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "medieval-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "arctic-leonard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import tarfile\n",
    "print(os.getcwd())\n",
    "\n",
    "# files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "# for f in files:\n",
    "#     print(f)\n",
    "\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "                   \n",
    "os.makedirs('export',exist_ok=True)\n",
    "os.makedirs('export/code',exist_ok=True)\n",
    "os.system('cp model.py export/code/')\n",
    "os.system('cp generate.py export/code/inference.py')\n",
    "os.system('cp model.pth export/')\n",
    "os.system('cp requirements.txt export/code/')\n",
    "os.chdir('export')\n",
    "os.system('tar -czvf ../model.tar.gz .')\n",
    "# make_tarfile('../model.tar.gz','./')\n",
    "os.chdir('../')\n",
    "\n",
    "s3_path_to_data  = sagemaker.Session().upload_data(bucket='pahts-test-bucket',\n",
    "                                              path=os.path.join(os.getcwd(),'model.tar.gz'),\n",
    "                                              key_prefix='linear_model_key')\n",
    "# s3_path_to_data  = sagemaker.Session().upload_data(bucket='pahts-test-bucket',\n",
    "#                                               path=os.path.join(os.getcwd(),'model.py'),\n",
    "#                                               key_prefix='linear_model_key')\n",
    "# s3_path_to_data  = sagemaker.Session().upload_data(bucket='pahts-test-bucket',\n",
    "#                                               path=os.path.join(os.getcwd(),'generate.py'),\n",
    "#                                               key_prefix='linear_model_key')\n",
    "# print(s3_path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-disability",
   "metadata": {},
   "source": [
    "### Exporting the model as an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "romantic-permission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-2-690762613439\n",
      "---------------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class RealTimePredictor has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.predictor import JSONSerializer, JSONDeserializer, Predictor\n",
    "\n",
    "class JSONPredictor(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(JSONPredictor, self).__init__(endpoint_name, sagemaker_session, JSONSerializer, JSONDeserializer)\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(bucket)\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data='s3://pahts-test-bucket/linear_model_key/model.tar.gz',\n",
    "                     role=role,\n",
    "                     entry_point='inference.py',\n",
    "                     framework_version='1.5.0',\n",
    "                     py_version='py3',\n",
    "                     source_dir='',\n",
    "                    predictor_cls=JSONPredictor)\n",
    "\n",
    "# Deploy model, https://aws.amazon.com/sagemaker/pricing/\n",
    "predictor = pytorch_model.deploy(instance_type='ml.t2.medium',initial_instance_count=1) #Cheapest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-charlotte",
   "metadata": {},
   "source": [
    "## Evaluate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "intellectual-generator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The json_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n",
      "tensor([4.9615])\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating')\n",
    "input = {'xvalue':2}\n",
    "input_json = json.dumps(input) \n",
    "\n",
    "# response = predictor.predict(input_json, initial_args={'ContentType': 'application/json'})\n",
    "response = predictor.predict(input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "suffering-terrace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Missing Authentication Token\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://runtime.sagemaker.us-east-2.amazonaws.com/endpoints/pytorch-inference-2021-02-19-22-17-20-522/invocations'\n",
    "myobj = {'xvalue': 2}\n",
    "\n",
    "x = requests.post(url, data = myobj)\n",
    "\n",
    "print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-rings",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
