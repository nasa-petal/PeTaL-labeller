{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"run_MATCH.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPYPYnhyZm4+3fpZk+ew5B9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Pp01HcdWYpum"},"source":["# Run MATCH\n","\n","Created by Eric Kong on 15 June 2021.\n","\n","In this notebook we reproduce the results of the MATCH algorithm (https://github.com/yuzhimanhua/MATCH).\n","\n","This notebook was originally run in Google Colaboratory with GPU acceleration."]},{"cell_type":"code","metadata":{"id":"N28hjL9WYoLS"},"source":["import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU4GmAtqzAWd","executionInfo":{"elapsed":196,"status":"ok","timestamp":1623944596182,"user":{"displayName":"Eric Kong","photoUrl":"","userId":"07341482379174037459"},"user_tz":420},"outputId":"541a4ada-875a-45ca-fbe1-2d72c341bbbd"},"source":["# If running on Google Colab: Mount drive and cd to workspace.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# NOTE: Replace DRIVE_PATH with the path you plan to clone MATCH into.\n","DRIVE_PATH = '/content/drive/Shareddrives/NASA'\n","%cd $DRIVE_PATH"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1o1d5YtSag3y","executionInfo":{"elapsed":170,"status":"ok","timestamp":1623941512958,"user":{"displayName":"Eric Kong","photoUrl":"","userId":"07341482379174037459"},"user_tz":420},"outputId":"26dbe96b-b5cd-482d-8e7e-da5de58f0359"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Thu Jun 17 14:51:52 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JzcNuQ-lyK7m","executionInfo":{"elapsed":1779,"status":"ok","timestamp":1623908066597,"user":{"displayName":"Eric Kong","photoUrl":"","userId":"07341482379174037459"},"user_tz":420},"outputId":"741f8a1a-93e9-43f0-bdf9-2d8747a5f01a"},"source":["if not os.path.exists('MATCH/'):\n","    !git clone https://github.com/yuzhimanhua/MATCH.git\n","else:a\n","    print(\"You have already cloned the MATCH repository.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'MATCH'...\n","remote: Enumerating objects: 156, done.\u001b[K\n","remote: Counting objects: 100% (156/156), done.\u001b[K\n","remote: Compressing objects: 100% (119/119), done.\u001b[K\n","remote: Total 156 (delta 69), reused 105 (delta 34), pack-reused 0\u001b[K\n","Receiving objects: 100% (156/156), 2.82 MiB | 15.28 MiB/s, done.\n","Resolving deltas: 100% (69/69), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TH4Sftq2eT5E","executionInfo":{"elapsed":201,"status":"ok","timestamp":1623944600256,"user":{"displayName":"Eric Kong","photoUrl":"","userId":"07341482379174037459"},"user_tz":420},"outputId":"5ca492a4-7576-4bab-b77e-e74e013ab134"},"source":["%cd ./MATCH\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/Shareddrives/MATCH Attempt/MATCH\n","configure      joint\tmain.py        preprocess.sh\t run_models.sh\n","deepxml        LICENSE\tMeSH\t       README.md\t transform_data.py\n","evaluation.py  MAG\tpreprocess.py  requirements.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUBqMk6KbvwC","executionInfo":{"elapsed":3121,"status":"ok","timestamp":1623944607096,"user":{"displayName":"Eric Kong","photoUrl":"","userId":"07341482379174037459"},"user_tz":420},"outputId":"7f257f27-ef01-4319-9d1f-58b1665a04f7"},"source":["# Install requirements in requirements.txt\n","!chmod 755 -R .\n","!pip3 install -r requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch==1.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n","Requirement already satisfied: torchvision==0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.4.0)\n","Requirement already satisfied: torchgpipe==0.0.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.0.5)\n","Requirement already satisfied: click==7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (7.0)\n","Requirement already satisfied: ruamel.yaml==0.16.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.16.5)\n","Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.16.2)\n","Requirement already satisfied: scipy==1.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.2.1)\n","Requirement already satisfied: scikit-learn==0.20.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.20.3)\n","Requirement already satisfied: gensim==3.7.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (3.7.2)\n","Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (4.31.1)\n","Requirement already satisfied: joblib==0.13.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.13.2)\n","Requirement already satisfied: logzero==1.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0->-r requirements.txt (line 2)) (7.1.2)\n","Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml==0.16.5->-r requirements.txt (line 5)) (0.2.2)\n","Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.7.2->-r requirements.txt (line 9)) (5.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dNemHI_6auA0","executionInfo":{"elapsed":267658,"status":"ok","timestamp":1623944883111,"user":{"displayName":"Eric Kong","photoUrl":"","userId":"07341482379174037459"},"user_tz":420},"outputId":"077ce78c-9144-413b-d5a2-59fc0a56bceb"},"source":["!./preprocess.sh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[I 210617 15:44:06 preprocess:28]\u001b[39m Vocab Size: 500000\n","\u001b[32m[I 210617 15:44:06 preprocess:30]\u001b[39m Getting Dataset: MAG/train_texts.txt Max Length: 500\n","tcmalloc: large alloc 2539503616 bytes == 0x558fac048000 @  0x7f91aba831e7 0x7f91a934bea1 0x7f91a93b0928 0x7f91a93b4070 0x7f91a93b45e5 0x7f91a944d40d 0x558ed8136d54 0x558ed8136a50 0x558ed81ab105 0x558ed81a54ae 0x558ed81383ea 0x558ed81aa7f0 0x558ed81a57ad 0x558ed81383ea 0x558ed81a63b5 0x558ed81a57ad 0x558ed81383ea 0x558ed81a63b5 0x558ed81a54ae 0x558ed8077e2c 0x558ed81a7bb5 0x558ed81a54ae 0x558ed8138c9f 0x558ed8138ea1 0x558ed81a7bb5 0x558ed813830a 0x558ed81a660e 0x558ed81a54ae 0x558ed8138a81 0x558ed8138ea1 0x558ed81a7bb5\n","\u001b[32m[I 210617 15:46:44 preprocess:32]\u001b[39m Size of Samples: 634874\n","\u001b[32m[I 210617 15:47:41 preprocess:28]\u001b[39m Vocab Size: 500000\n","\u001b[32m[I 210617 15:47:41 preprocess:30]\u001b[39m Getting Dataset: MAG/test_texts.txt Max Length: 500\n","\u001b[32m[I 210617 15:47:56 preprocess:32]\u001b[39m Size of Samples: 70533\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"LahoKA3ofc2w","outputId":"74303e99-cf22-4a18-da53-5d17d01a3eb5"},"source":["!./run_models.sh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[I 210617 15:48:17 main:32]\u001b[39m Model Name: MATCH\n","\u001b[32m[I 210617 15:48:17 main:35]\u001b[39m Loading Training and Validation Set\n","tcmalloc: large alloc 2539503616 bytes == 0x55777a22e000 @  0x7f4bd84601e7 0x7f4bd5d28ea1 0x7f4bd5d92b75 0x7f4bd5d9370e 0x7f4bd5e2c71e 0x55775d768d54 0x55775d768a50 0x55775d7dd105 0x55775d7d74ae 0x55775d76a3ea 0x55775d7d932a 0x55775d7d74ae 0x55775d76a3ea 0x55775d7d932a 0x55775d7d74ae 0x55775d76a3ea 0x55775d7d83b5 0x55775d7d74ae 0x55775d6a9e2c 0x55775d7d9bb5 0x55775d7d74ae 0x55775d76ac9f 0x55775d76aea1 0x55775d7d9bb5 0x55775d76a30a 0x55775d7d860e 0x55775d7d74ae 0x55775d76aa81 0x55775d76aea1 0x55775d7d9bb5 0x55775d7d74ae\n","tcmalloc: large alloc 2257362944 bytes == 0x5578127f4000 @  0x7f4bd84601e7 0x7f4bd5d28ea1 0x7f4bd5d8d928 0x7f4bd5d8da43 0x7f4bd5ddd2d4 0x7f4bd5e1cb90 0x55775d768d54 0x55775d768a50 0x55775d7dd105 0x55775d7d77ad 0x55775d76a3ea 0x55775d7d83b5 0x55775d85aec8 0x55775d850d8e 0x55775d840b95 0x55775d777a34 0x55775d7a8cc4 0x55775d769462 0x55775d7dc715 0x55775d7d77ad 0x55775d76a3ea 0x55775d7d932a 0x55775d7d74ae 0x55775d6a9e2c 0x55775d7d9bb5 0x55775d7d74ae 0x55775d76ac9f 0x55775d76aea1 0x55775d7d9bb5 0x55775d76a30a 0x55775d7d860e\n","\u001b[32m[I 210617 15:48:47 main:47]\u001b[39m Number of Labels: 15308\n","\u001b[32m[I 210617 15:48:47 main:48]\u001b[39m Size of Training Set: 564340\n","\u001b[32m[I 210617 15:48:47 main:49]\u001b[39m Size of Validation Set: 70534\n","\u001b[32m[I 210617 15:48:54 main:66]\u001b[39m Number of Edges: 26491\n","\u001b[32m[I 210617 15:48:54 main:68]\u001b[39m Training\n","\u001b[32m[I 210617 15:52:33 models:110]\u001b[39m 0 25600 train loss: 0.0265692 valid loss: 0.0023821 P@1: 0.14950 P@3: 0.13431 P@5: 0.11884 N@3: 0.14536 N@5: 0.14271 early stop: 0\n","\u001b[32m[I 210617 15:55:57 models:110]\u001b[39m 0 51200 train loss: 0.0023748 valid loss: 0.0023726 P@1: 0.15261 P@3: 0.13432 P@5: 0.11884 N@3: 0.14591 N@5: 0.14319 early stop: 0\n","\u001b[32m[I 210617 15:59:21 models:110]\u001b[39m 0 76800 train loss: 0.0023770 valid loss: 0.0023646 P@1: 0.14959 P@3: 0.14534 P@5: 0.12222 N@3: 0.15358 N@5: 0.14813 early stop: 0\n","\u001b[32m[I 210617 16:02:44 models:110]\u001b[39m 0 102400 train loss: 0.0023563 valid loss: 0.0023499 P@1: 0.16239 P@3: 0.14967 P@5: 0.12749 N@3: 0.16323 N@5: 0.15912 early stop: 0\n","\u001b[32m[I 210617 16:06:08 models:110]\u001b[39m 0 128000 train loss: 0.0023532 valid loss: 0.0023100 P@1: 0.22043 P@3: 0.19512 P@5: 0.15106 N@3: 0.21118 N@5: 0.19175 early stop: 0\n","\u001b[32m[I 210617 16:09:30 models:110]\u001b[39m 0 153600 train loss: 0.0022600 valid loss: 0.0022188 P@1: 0.28236 P@3: 0.22166 P@5: 0.17591 N@3: 0.24681 N@5: 0.22702 early stop: 0\n","\u001b[32m[I 210617 16:12:52 models:110]\u001b[39m 0 179200 train loss: 0.0022004 valid loss: 0.0021808 P@1: 0.29547 P@3: 0.23071 P@5: 0.18188 N@3: 0.25665 N@5: 0.23578 early stop: 0\n","\u001b[32m[I 210617 16:16:13 models:110]\u001b[39m 0 204800 train loss: 0.0021617 valid loss: 0.0021420 P@1: 0.32641 P@3: 0.23688 P@5: 0.18348 N@3: 0.26946 N@5: 0.24493 early stop: 0\n","\u001b[32m[I 210617 16:19:36 models:110]\u001b[39m 0 230400 train loss: 0.0021457 valid loss: 0.0021426 P@1: 0.32132 P@3: 0.23919 P@5: 0.18677 N@3: 0.27180 N@5: 0.24823 early stop: 0\n","\u001b[32m[I 210617 16:22:58 models:110]\u001b[39m 0 256000 train loss: 0.0021209 valid loss: 0.0020963 P@1: 0.35172 P@3: 0.26092 P@5: 0.19503 N@3: 0.29614 N@5: 0.26304 early stop: 0\n","\u001b[32m[I 210617 16:26:20 models:110]\u001b[39m 0 281600 train loss: 0.0020804 valid loss: 0.0020582 P@1: 0.36778 P@3: 0.27336 P@5: 0.20879 N@3: 0.31183 N@5: 0.28089 early stop: 0\n","\u001b[32m[I 210617 16:29:40 models:110]\u001b[39m 0 307200 train loss: 0.0020335 valid loss: 0.0019928 P@1: 0.42092 P@3: 0.29898 P@5: 0.22828 N@3: 0.34537 N@5: 0.31121 early stop: 0\n","\u001b[32m[I 210617 16:33:02 models:110]\u001b[39m 0 332800 train loss: 0.0019721 valid loss: 0.0019144 P@1: 0.48201 P@3: 0.33649 P@5: 0.25268 N@3: 0.39146 N@5: 0.34977 early stop: 0\n","\u001b[32m[I 210617 16:36:24 models:110]\u001b[39m 0 358400 train loss: 0.0019078 valid loss: 0.0018660 P@1: 0.50603 P@3: 0.34696 P@5: 0.26208 N@3: 0.40541 N@5: 0.36294 early stop: 0\n","\u001b[32m[I 210617 16:39:47 models:110]\u001b[39m 0 384000 train loss: 0.0018624 valid loss: 0.0018374 P@1: 0.52631 P@3: 0.35881 P@5: 0.26892 N@3: 0.42091 N@5: 0.37551 early stop: 0\n","\u001b[32m[I 210617 16:43:08 models:110]\u001b[39m 0 409600 train loss: 0.0018494 valid loss: 0.0018107 P@1: 0.54036 P@3: 0.36706 P@5: 0.27759 N@3: 0.43100 N@5: 0.38672 early stop: 0\n","\u001b[32m[I 210617 16:46:30 models:110]\u001b[39m 0 435200 train loss: 0.0018314 valid loss: 0.0018014 P@1: 0.54781 P@3: 0.37196 P@5: 0.27996 N@3: 0.43717 N@5: 0.39110 early stop: 0\n","\u001b[32m[I 210617 16:49:52 models:110]\u001b[39m 0 460800 train loss: 0.0018039 valid loss: 0.0017720 P@1: 0.56476 P@3: 0.37900 P@5: 0.28616 N@3: 0.44721 N@5: 0.40062 early stop: 0\n","\u001b[32m[I 210617 16:53:14 models:110]\u001b[39m 0 486400 train loss: 0.0017857 valid loss: 0.0017528 P@1: 0.57863 P@3: 0.38857 P@5: 0.29338 N@3: 0.45818 N@5: 0.41038 early stop: 0\n","\u001b[32m[I 210617 16:56:35 models:110]\u001b[39m 0 512000 train loss: 0.0017501 valid loss: 0.0017372 P@1: 0.58402 P@3: 0.39438 P@5: 0.29893 N@3: 0.46393 N@5: 0.41597 early stop: 0\n","\u001b[32m[I 210617 16:59:57 models:110]\u001b[39m 0 537600 train loss: 0.0017435 valid loss: 0.0017118 P@1: 0.59217 P@3: 0.39886 P@5: 0.30266 N@3: 0.46961 N@5: 0.42156 early stop: 0\n","\u001b[32m[I 210617 17:03:19 models:110]\u001b[39m 0 563200 train loss: 0.0017158 valid loss: 0.0016959 P@1: 0.59981 P@3: 0.40828 P@5: 0.30906 N@3: 0.47908 N@5: 0.42963 early stop: 0\n","\u001b[32m[I 210617 17:06:42 models:110]\u001b[39m 1 24320 train loss: 0.0016824 valid loss: 0.0016590 P@1: 0.61375 P@3: 0.41818 P@5: 0.31990 N@3: 0.49059 N@5: 0.44245 early stop: 0\n","\u001b[32m[I 210617 17:10:04 models:110]\u001b[39m 1 49920 train loss: 0.0016564 valid loss: 0.0016372 P@1: 0.62744 P@3: 0.42740 P@5: 0.32534 N@3: 0.50170 N@5: 0.45171 early stop: 0\n","\u001b[32m[I 210617 17:13:27 models:110]\u001b[39m 1 75520 train loss: 0.0016280 valid loss: 0.0016063 P@1: 0.64141 P@3: 0.43951 P@5: 0.33472 N@3: 0.51480 N@5: 0.46378 early stop: 0\n","\u001b[32m[I 210617 17:16:49 models:110]\u001b[39m 1 101120 train loss: 0.0016009 valid loss: 0.0015791 P@1: 0.65227 P@3: 0.44835 P@5: 0.34204 N@3: 0.52492 N@5: 0.47337 early stop: 0\n","\u001b[32m[I 210617 17:20:12 models:110]\u001b[39m 1 126720 train loss: 0.0015781 valid loss: 0.0015600 P@1: 0.66033 P@3: 0.45637 P@5: 0.34943 N@3: 0.53316 N@5: 0.48174 early stop: 0\n","\u001b[32m[I 210617 17:23:35 models:110]\u001b[39m 1 152320 train loss: 0.0015549 valid loss: 0.0015378 P@1: 0.67156 P@3: 0.46345 P@5: 0.35537 N@3: 0.54216 N@5: 0.49071 early stop: 0\n","\u001b[32m[I 210617 17:26:58 models:110]\u001b[39m 1 177920 train loss: 0.0015375 valid loss: 0.0015130 P@1: 0.68136 P@3: 0.47286 P@5: 0.36404 N@3: 0.55178 N@5: 0.50038 early stop: 0\n","\u001b[32m[I 210617 17:30:21 models:110]\u001b[39m 1 203520 train loss: 0.0015060 valid loss: 0.0014948 P@1: 0.68700 P@3: 0.47965 P@5: 0.36992 N@3: 0.55900 N@5: 0.50762 early stop: 0\n","\u001b[32m[I 210617 17:33:46 models:110]\u001b[39m 1 229120 train loss: 0.0014988 valid loss: 0.0014775 P@1: 0.69199 P@3: 0.48550 P@5: 0.37434 N@3: 0.56471 N@5: 0.51295 early stop: 0\n","\u001b[32m[I 210617 17:37:10 models:110]\u001b[39m 1 254720 train loss: 0.0014922 valid loss: 0.0014642 P@1: 0.69822 P@3: 0.49187 P@5: 0.37987 N@3: 0.57169 N@5: 0.51998 early stop: 0\n","\u001b[32m[I 210617 17:40:34 models:110]\u001b[39m 1 280320 train loss: 0.0014746 valid loss: 0.0014556 P@1: 0.69997 P@3: 0.49482 P@5: 0.38262 N@3: 0.57524 N@5: 0.52398 early stop: 0\n","\u001b[32m[I 210617 17:43:59 models:110]\u001b[39m 1 305920 train loss: 0.0014568 valid loss: 0.0014346 P@1: 0.70852 P@3: 0.50125 P@5: 0.38899 N@3: 0.58215 N@5: 0.53133 early stop: 0\n","\u001b[32m[I 210617 17:47:24 models:110]\u001b[39m 1 331520 train loss: 0.0014452 valid loss: 0.0014233 P@1: 0.71346 P@3: 0.50791 P@5: 0.39326 N@3: 0.58895 N@5: 0.53687 early stop: 0\n","\u001b[32m[I 210617 17:50:48 models:110]\u001b[39m 1 357120 train loss: 0.0014329 valid loss: 0.0014109 P@1: 0.71448 P@3: 0.50955 P@5: 0.39553 N@3: 0.59106 N@5: 0.53975 early stop: 0\n","\u001b[32m[I 210617 17:54:13 models:110]\u001b[39m 1 382720 train loss: 0.0014245 valid loss: 0.0013965 P@1: 0.72138 P@3: 0.51770 P@5: 0.40278 N@3: 0.59938 N@5: 0.54824 early stop: 0\n","\u001b[32m[I 210617 17:57:37 models:110]\u001b[39m 1 408320 train loss: 0.0014104 valid loss: 0.0013856 P@1: 0.72667 P@3: 0.52247 P@5: 0.40582 N@3: 0.60475 N@5: 0.55278 early stop: 0\n","\u001b[32m[I 210617 18:01:01 models:110]\u001b[39m 1 433920 train loss: 0.0013963 valid loss: 0.0013689 P@1: 0.73074 P@3: 0.52864 P@5: 0.41113 N@3: 0.61083 N@5: 0.55897 early stop: 0\n","\u001b[32m[I 210617 18:04:26 models:110]\u001b[39m 1 459520 train loss: 0.0013808 valid loss: 0.0013642 P@1: 0.73428 P@3: 0.52987 P@5: 0.41247 N@3: 0.61289 N@5: 0.56131 early stop: 0\n","\u001b[32m[I 210617 18:07:51 models:110]\u001b[39m 1 485120 train loss: 0.0013666 valid loss: 0.0013488 P@1: 0.73950 P@3: 0.53607 P@5: 0.41801 N@3: 0.61949 N@5: 0.56798 early stop: 0\n","\u001b[32m[I 210617 18:11:15 models:110]\u001b[39m 1 510720 train loss: 0.0013648 valid loss: 0.0013369 P@1: 0.74662 P@3: 0.54214 P@5: 0.42243 N@3: 0.62642 N@5: 0.57422 early stop: 0\n","\u001b[32m[I 210617 18:14:40 models:110]\u001b[39m 1 536320 train loss: 0.0013452 valid loss: 0.0013256 P@1: 0.75074 P@3: 0.54653 P@5: 0.42656 N@3: 0.63072 N@5: 0.57880 early stop: 0\n","\u001b[32m[I 210617 18:18:05 models:110]\u001b[39m 1 561920 train loss: 0.0013250 valid loss: 0.0013153 P@1: 0.75053 P@3: 0.55075 P@5: 0.42991 N@3: 0.63460 N@5: 0.58268 early stop: 0\n","\u001b[32m[I 210617 18:21:31 models:110]\u001b[39m 2 23040 train loss: 0.0012830 valid loss: 0.0013054 P@1: 0.75583 P@3: 0.55582 P@5: 0.43489 N@3: 0.63969 N@5: 0.58816 early stop: 0\n","\u001b[32m[I 210617 18:24:55 models:110]\u001b[39m 2 48640 train loss: 0.0012741 valid loss: 0.0012989 P@1: 0.76063 P@3: 0.55852 P@5: 0.43605 N@3: 0.64352 N@5: 0.59083 early stop: 0\n","\u001b[32m[I 210617 18:28:19 models:110]\u001b[39m 2 74240 train loss: 0.0012666 valid loss: 0.0012838 P@1: 0.77105 P@3: 0.56806 P@5: 0.44364 N@3: 0.65364 N@5: 0.60039 early stop: 0\n","\u001b[32m[I 210617 18:31:41 models:110]\u001b[39m 2 99840 train loss: 0.0012571 valid loss: 0.0012665 P@1: 0.77526 P@3: 0.57240 P@5: 0.44893 N@3: 0.65871 N@5: 0.60688 early stop: 0\n","\u001b[32m[I 210617 18:35:04 models:110]\u001b[39m 2 125440 train loss: 0.0012584 valid loss: 0.0012588 P@1: 0.78029 P@3: 0.57746 P@5: 0.45228 N@3: 0.66394 N@5: 0.61118 early stop: 0\n","\u001b[32m[I 210617 18:38:27 models:110]\u001b[39m 2 151040 train loss: 0.0012406 valid loss: 0.0012501 P@1: 0.78033 P@3: 0.58119 P@5: 0.45586 N@3: 0.66727 N@5: 0.61500 early stop: 0\n","\u001b[32m[I 210617 18:41:50 models:110]\u001b[39m 2 176640 train loss: 0.0012300 valid loss: 0.0012360 P@1: 0.78829 P@3: 0.58915 P@5: 0.46187 N@3: 0.67578 N@5: 0.62260 early stop: 0\n","\u001b[32m[I 210617 18:45:13 models:110]\u001b[39m 2 202240 train loss: 0.0012235 valid loss: 0.0012298 P@1: 0.79409 P@3: 0.59476 P@5: 0.46588 N@3: 0.68183 N@5: 0.62803 early stop: 0\n","\u001b[32m[I 210617 18:48:35 models:110]\u001b[39m 2 227840 train loss: 0.0012101 valid loss: 0.0012141 P@1: 0.80238 P@3: 0.60216 P@5: 0.47143 N@3: 0.68977 N@5: 0.63518 early stop: 0\n","\u001b[32m[I 210617 18:51:57 models:110]\u001b[39m 2 253440 train loss: 0.0011967 valid loss: 0.0012073 P@1: 0.81131 P@3: 0.60747 P@5: 0.47533 N@3: 0.69682 N@5: 0.64188 early stop: 0\n","\u001b[32m[I 210617 18:55:20 models:110]\u001b[39m 2 279040 train loss: 0.0011927 valid loss: 0.0012004 P@1: 0.81344 P@3: 0.61079 P@5: 0.47872 N@3: 0.70005 N@5: 0.64531 early stop: 0\n","\u001b[32m[I 210617 18:58:42 models:110]\u001b[39m 2 304640 train loss: 0.0011787 valid loss: 0.0011803 P@1: 0.81935 P@3: 0.61729 P@5: 0.48515 N@3: 0.70733 N@5: 0.65332 early stop: 0\n","\u001b[32m[I 210617 19:02:04 models:110]\u001b[39m 2 330240 train loss: 0.0011766 valid loss: 0.0011776 P@1: 0.82491 P@3: 0.62133 P@5: 0.48763 N@3: 0.71186 N@5: 0.65699 early stop: 0\n","\u001b[32m[I 210617 19:05:26 models:110]\u001b[39m 2 355840 train loss: 0.0011581 valid loss: 0.0011581 P@1: 0.82719 P@3: 0.62689 P@5: 0.49248 N@3: 0.71690 N@5: 0.66201 early stop: 0\n","\u001b[32m[I 210617 19:08:49 models:110]\u001b[39m 2 381440 train loss: 0.0011503 valid loss: 0.0011487 P@1: 0.83531 P@3: 0.63216 P@5: 0.49667 N@3: 0.72335 N@5: 0.66820 early stop: 0\n","\u001b[32m[I 210617 19:12:12 models:110]\u001b[39m 2 407040 train loss: 0.0011422 valid loss: 0.0011384 P@1: 0.83840 P@3: 0.63867 P@5: 0.50205 N@3: 0.72952 N@5: 0.67415 early stop: 0\n","\u001b[32m[I 210617 19:15:34 models:110]\u001b[39m 2 432640 train loss: 0.0011397 valid loss: 0.0011285 P@1: 0.84339 P@3: 0.64390 P@5: 0.50727 N@3: 0.73458 N@5: 0.67964 early stop: 0\n","\u001b[32m[I 210617 19:18:57 models:110]\u001b[39m 2 458240 train loss: 0.0011229 valid loss: 0.0011206 P@1: 0.84792 P@3: 0.64789 P@5: 0.51001 N@3: 0.73919 N@5: 0.68368 early stop: 0\n","\u001b[32m[I 210617 19:22:20 models:110]\u001b[39m 2 483840 train loss: 0.0011186 valid loss: 0.0011147 P@1: 0.85226 P@3: 0.65158 P@5: 0.51345 N@3: 0.74335 N@5: 0.68790 early stop: 0\n","\u001b[32m[I 210617 19:25:44 models:110]\u001b[39m 2 509440 train loss: 0.0011007 valid loss: 0.0010974 P@1: 0.85496 P@3: 0.65613 P@5: 0.51775 N@3: 0.74759 N@5: 0.69241 early stop: 0\n","\u001b[32m[I 210617 19:29:07 models:110]\u001b[39m 2 535040 train loss: 0.0011005 valid loss: 0.0010905 P@1: 0.86056 P@3: 0.66233 P@5: 0.52277 N@3: 0.75404 N@5: 0.69851 early stop: 0\n","\u001b[32m[I 210617 19:32:30 models:110]\u001b[39m 2 560640 train loss: 0.0010961 valid loss: 0.0010916 P@1: 0.86225 P@3: 0.66584 P@5: 0.52429 N@3: 0.75749 N@5: 0.70104 early stop: 0\n","\u001b[32m[I 210617 19:35:55 models:110]\u001b[39m 3 21760 train loss: 0.0010145 valid loss: 0.0010886 P@1: 0.86313 P@3: 0.66647 P@5: 0.52666 N@3: 0.75797 N@5: 0.70273 early stop: 0\n","\u001b[32m[I 210617 19:39:20 models:110]\u001b[39m 3 47360 train loss: 0.0009862 valid loss: 0.0010812 P@1: 0.86208 P@3: 0.67008 P@5: 0.53058 N@3: 0.76091 N@5: 0.70631 early stop: 0\n","\u001b[32m[I 210617 19:42:42 models:110]\u001b[39m 3 72960 train loss: 0.0009927 valid loss: 0.0010753 P@1: 0.86313 P@3: 0.67141 P@5: 0.53181 N@3: 0.76174 N@5: 0.70687 early stop: 0\n","\u001b[32m[I 210617 19:46:07 models:110]\u001b[39m 3 98560 train loss: 0.0009866 valid loss: 0.0010806 P@1: 0.86510 P@3: 0.67196 P@5: 0.53157 N@3: 0.76246 N@5: 0.70719 early stop: 0\n","\u001b[32m[I 210617 19:49:32 models:110]\u001b[39m 3 124160 train loss: 0.0009774 valid loss: 0.0010677 P@1: 0.86860 P@3: 0.67909 P@5: 0.53724 N@3: 0.76967 N@5: 0.71397 early stop: 0\n","\u001b[32m[I 210617 19:52:54 models:110]\u001b[39m 3 149760 train loss: 0.0009804 valid loss: 0.0010555 P@1: 0.87090 P@3: 0.68016 P@5: 0.53896 N@3: 0.77075 N@5: 0.71548 early stop: 0\n","\u001b[32m[I 210617 19:56:15 models:110]\u001b[39m 3 175360 train loss: 0.0009753 valid loss: 0.0010526 P@1: 0.87322 P@3: 0.68519 P@5: 0.54404 N@3: 0.77538 N@5: 0.72071 early stop: 0\n","\u001b[32m[I 210617 19:59:39 models:110]\u001b[39m 3 200960 train loss: 0.0009741 valid loss: 0.0010398 P@1: 0.87507 P@3: 0.68979 P@5: 0.54780 N@3: 0.77950 N@5: 0.72456 early stop: 0\n","\u001b[32m[I 210617 20:03:02 models:110]\u001b[39m 3 226560 train loss: 0.0009578 valid loss: 0.0010343 P@1: 0.87827 P@3: 0.69188 P@5: 0.55013 N@3: 0.78214 N@5: 0.72750 early stop: 0\n","\u001b[32m[I 210617 20:06:27 models:110]\u001b[39m 3 252160 train loss: 0.0009562 valid loss: 0.0010280 P@1: 0.88091 P@3: 0.69474 P@5: 0.55172 N@3: 0.78500 N@5: 0.72967 early stop: 0\n","\u001b[32m[I 210617 20:09:50 models:110]\u001b[39m 3 277760 train loss: 0.0009481 valid loss: 0.0010191 P@1: 0.88289 P@3: 0.69971 P@5: 0.55683 N@3: 0.78985 N@5: 0.73521 early stop: 0\n","\u001b[32m[I 210617 20:13:13 models:110]\u001b[39m 3 303360 train loss: 0.0009507 valid loss: 0.0010119 P@1: 0.88111 P@3: 0.70076 P@5: 0.55830 N@3: 0.78989 N@5: 0.73565 early stop: 0\n","\u001b[32m[I 210617 20:16:39 models:110]\u001b[39m 3 328960 train loss: 0.0009392 valid loss: 0.0009986 P@1: 0.88567 P@3: 0.70567 P@5: 0.56280 N@3: 0.79496 N@5: 0.74072 early stop: 0\n","\u001b[32m[I 210617 20:20:05 models:110]\u001b[39m 3 354560 train loss: 0.0009372 valid loss: 0.0009939 P@1: 0.88489 P@3: 0.70732 P@5: 0.56644 N@3: 0.79614 N@5: 0.74360 early stop: 0\n","\u001b[32m[I 210617 20:23:28 models:110]\u001b[39m 3 380160 train loss: 0.0009356 valid loss: 0.0009856 P@1: 0.88811 P@3: 0.71212 P@5: 0.56981 N@3: 0.80094 N@5: 0.74789 early stop: 0\n","\u001b[32m[I 210617 20:26:50 models:110]\u001b[39m 3 405760 train loss: 0.0009234 valid loss: 0.0009790 P@1: 0.88977 P@3: 0.71291 P@5: 0.57123 N@3: 0.80212 N@5: 0.74946 early stop: 0\n","\u001b[32m[I 210617 20:30:12 models:110]\u001b[39m 3 431360 train loss: 0.0009157 valid loss: 0.0009711 P@1: 0.88959 P@3: 0.71445 P@5: 0.57281 N@3: 0.80301 N@5: 0.75078 early stop: 0\n","\u001b[32m[I 210617 20:33:34 models:110]\u001b[39m 3 456960 train loss: 0.0009132 valid loss: 0.0009629 P@1: 0.89317 P@3: 0.72194 P@5: 0.58005 N@3: 0.81004 N@5: 0.75830 early stop: 0\n","\u001b[32m[I 210617 20:36:54 models:110]\u001b[39m 3 482560 train loss: 0.0009110 valid loss: 0.0009569 P@1: 0.89285 P@3: 0.72096 P@5: 0.58038 N@3: 0.80921 N@5: 0.75818 early stop: 1\n","\u001b[32m[I 210617 20:40:15 models:110]\u001b[39m 3 508160 train loss: 0.0009077 valid loss: 0.0009474 P@1: 0.89523 P@3: 0.72593 P@5: 0.58452 N@3: 0.81415 N@5: 0.76286 early stop: 0\n","\u001b[32m[I 210617 20:43:37 models:110]\u001b[39m 3 533760 train loss: 0.0008964 valid loss: 0.0009401 P@1: 0.89666 P@3: 0.72788 P@5: 0.58682 N@3: 0.81564 N@5: 0.76504 early stop: 0\n","\u001b[32m[I 210617 20:46:58 models:110]\u001b[39m 3 559360 train loss: 0.0008934 valid loss: 0.0009288 P@1: 0.89811 P@3: 0.73080 P@5: 0.58948 N@3: 0.81844 N@5: 0.76792 early stop: 0\n","\u001b[32m[I 210617 20:47:34 models:142]\u001b[39m SWA Initializing\n","\u001b[32m[I 210617 20:50:20 models:110]\u001b[39m 4 20480 train loss: 0.0007784 valid loss: 0.0009100 P@1: 0.90155 P@3: 0.73876 P@5: 0.59822 N@3: 0.82564 N@5: 0.77642 early stop: 0\n","\u001b[32m[I 210617 20:53:40 models:110]\u001b[39m 4 46080 train loss: 0.0007484 valid loss: 0.0009058 P@1: 0.90256 P@3: 0.74187 P@5: 0.60096 N@3: 0.82841 N@5: 0.77909 early stop: 0\n","\u001b[32m[I 210617 20:56:59 models:110]\u001b[39m 4 71680 train loss: 0.0007517 valid loss: 0.0008998 P@1: 0.90393 P@3: 0.74375 P@5: 0.60412 N@3: 0.83023 N@5: 0.78199 early stop: 0\n","\u001b[32m[I 210617 21:00:18 models:110]\u001b[39m 4 97280 train loss: 0.0007541 valid loss: 0.0008971 P@1: 0.90423 P@3: 0.74486 P@5: 0.60574 N@3: 0.83118 N@5: 0.78347 early stop: 0\n","\u001b[32m[I 210617 21:03:37 models:110]\u001b[39m 4 122880 train loss: 0.0007429 valid loss: 0.0008944 P@1: 0.90531 P@3: 0.74640 P@5: 0.60714 N@3: 0.83262 N@5: 0.78493 early stop: 0\n","\u001b[32m[I 210617 21:06:54 models:110]\u001b[39m 4 148480 train loss: 0.0007556 valid loss: 0.0008904 P@1: 0.90579 P@3: 0.74751 P@5: 0.60857 N@3: 0.83363 N@5: 0.78626 early stop: 0\n","\u001b[32m[I 210617 21:10:14 models:110]\u001b[39m 4 174080 train loss: 0.0007498 valid loss: 0.0008869 P@1: 0.90687 P@3: 0.74875 P@5: 0.60960 N@3: 0.83488 N@5: 0.78746 early stop: 0\n","\u001b[32m[I 210617 21:13:34 models:110]\u001b[39m 4 199680 train loss: 0.0007422 valid loss: 0.0008839 P@1: 0.90726 P@3: 0.75003 P@5: 0.61076 N@3: 0.83607 N@5: 0.78874 early stop: 0\n","\u001b[32m[I 210617 21:16:55 models:110]\u001b[39m 4 225280 train loss: 0.0007445 valid loss: 0.0008812 P@1: 0.90779 P@3: 0.75085 P@5: 0.61173 N@3: 0.83680 N@5: 0.78959 early stop: 0\n","\u001b[32m[I 210617 21:20:16 models:110]\u001b[39m 4 250880 train loss: 0.0007428 valid loss: 0.0008780 P@1: 0.90803 P@3: 0.75143 P@5: 0.61276 N@3: 0.83737 N@5: 0.79056 early stop: 0\n","\u001b[32m[I 210617 21:23:38 models:110]\u001b[39m 4 276480 train loss: 0.0007412 valid loss: 0.0008755 P@1: 0.90901 P@3: 0.75237 P@5: 0.61398 N@3: 0.83828 N@5: 0.79176 early stop: 0\n","\u001b[32m[I 210617 21:27:00 models:110]\u001b[39m 4 302080 train loss: 0.0007415 valid loss: 0.0008720 P@1: 0.90962 P@3: 0.75381 P@5: 0.61512 N@3: 0.83962 N@5: 0.79297 early stop: 0\n","\u001b[32m[I 210617 21:30:20 models:110]\u001b[39m 4 327680 train loss: 0.0007431 valid loss: 0.0008690 P@1: 0.90997 P@3: 0.75457 P@5: 0.61608 N@3: 0.84037 N@5: 0.79395 early stop: 0\n","\u001b[32m[I 210617 21:33:40 models:110]\u001b[39m 4 353280 train loss: 0.0007445 valid loss: 0.0008660 P@1: 0.91045 P@3: 0.75539 P@5: 0.61724 N@3: 0.84112 N@5: 0.79500 early stop: 0\n","\u001b[32m[I 210617 21:37:00 models:110]\u001b[39m 4 378880 train loss: 0.0007463 valid loss: 0.0008628 P@1: 0.91075 P@3: 0.75634 P@5: 0.61835 N@3: 0.84192 N@5: 0.79600 early stop: 0\n","\u001b[32m[I 210617 21:40:19 models:110]\u001b[39m 4 404480 train loss: 0.0007477 valid loss: 0.0008595 P@1: 0.91104 P@3: 0.75694 P@5: 0.61926 N@3: 0.84256 N@5: 0.79693 early stop: 0\n","\u001b[32m[I 210617 21:43:40 models:110]\u001b[39m 4 430080 train loss: 0.0007382 valid loss: 0.0008568 P@1: 0.91122 P@3: 0.75763 P@5: 0.62009 N@3: 0.84315 N@5: 0.79769 early stop: 0\n","\u001b[32m[I 210617 21:47:01 models:110]\u001b[39m 4 455680 train loss: 0.0007361 valid loss: 0.0008543 P@1: 0.91150 P@3: 0.75807 P@5: 0.62095 N@3: 0.84357 N@5: 0.79843 early stop: 0\n","\u001b[32m[I 210617 21:50:20 models:110]\u001b[39m 4 481280 train loss: 0.0007377 valid loss: 0.0008513 P@1: 0.91184 P@3: 0.75879 P@5: 0.62185 N@3: 0.84425 N@5: 0.79934 early stop: 0\n","\u001b[32m[I 210617 21:53:39 models:110]\u001b[39m 4 506880 train loss: 0.0007387 valid loss: 0.0008486 P@1: 0.91237 P@3: 0.75965 P@5: 0.62288 N@3: 0.84514 N@5: 0.80039 early stop: 0\n","\u001b[32m[I 210617 21:56:57 models:110]\u001b[39m 4 532480 train loss: 0.0007365 valid loss: 0.0008457 P@1: 0.91257 P@3: 0.76034 P@5: 0.62346 N@3: 0.84574 N@5: 0.80097 early stop: 0\n","\u001b[32m[I 210617 22:00:16 models:110]\u001b[39m 4 558080 train loss: 0.0007327 valid loss: 0.0008433 P@1: 0.91295 P@3: 0.76108 P@5: 0.62435 N@3: 0.84638 N@5: 0.80178 early stop: 0\n","\u001b[32m[I 210617 22:03:40 models:110]\u001b[39m 5 19200 train loss: 0.0006103 valid loss: 0.0008432 P@1: 0.91326 P@3: 0.76140 P@5: 0.62480 N@3: 0.84670 N@5: 0.80222 early stop: 0\n","\u001b[32m[I 210617 22:07:00 models:110]\u001b[39m 5 44800 train loss: 0.0005825 valid loss: 0.0008429 P@1: 0.91356 P@3: 0.76176 P@5: 0.62510 N@3: 0.84700 N@5: 0.80254 early stop: 0\n","\u001b[32m[I 210617 22:10:19 models:110]\u001b[39m 5 70400 train loss: 0.0005801 valid loss: 0.0008427 P@1: 0.91380 P@3: 0.76238 P@5: 0.62546 N@3: 0.84750 N@5: 0.80288 early stop: 0\n","\u001b[32m[I 210617 22:13:40 models:110]\u001b[39m 5 96000 train loss: 0.0005884 valid loss: 0.0008424 P@1: 0.91376 P@3: 0.76257 P@5: 0.62580 N@3: 0.84765 N@5: 0.80316 early stop: 0\n","\u001b[32m[I 210617 22:17:00 models:110]\u001b[39m 5 121600 train loss: 0.0005847 valid loss: 0.0008422 P@1: 0.91404 P@3: 0.76280 P@5: 0.62604 N@3: 0.84790 N@5: 0.80340 early stop: 0\n","\u001b[32m[I 210617 22:20:23 models:110]\u001b[39m 5 147200 train loss: 0.0005903 valid loss: 0.0008419 P@1: 0.91417 P@3: 0.76310 P@5: 0.62651 N@3: 0.84815 N@5: 0.80383 early stop: 0\n","\u001b[32m[I 210617 22:23:43 models:110]\u001b[39m 5 172800 train loss: 0.0005914 valid loss: 0.0008418 P@1: 0.91428 P@3: 0.76326 P@5: 0.62685 N@3: 0.84831 N@5: 0.80414 early stop: 0\n","\u001b[32m[I 210617 22:27:06 models:110]\u001b[39m 5 198400 train loss: 0.0005954 valid loss: 0.0008413 P@1: 0.91411 P@3: 0.76355 P@5: 0.62715 N@3: 0.84847 N@5: 0.80434 early stop: 0\n","\u001b[32m[I 210617 22:30:29 models:110]\u001b[39m 5 224000 train loss: 0.0005967 valid loss: 0.0008410 P@1: 0.91428 P@3: 0.76393 P@5: 0.62747 N@3: 0.84880 N@5: 0.80464 early stop: 0\n","\u001b[32m[I 210617 22:33:51 models:110]\u001b[39m 5 249600 train loss: 0.0005987 valid loss: 0.0008403 P@1: 0.91451 P@3: 0.76426 P@5: 0.62780 N@3: 0.84908 N@5: 0.80495 early stop: 0\n","\u001b[32m[I 210617 22:37:12 models:110]\u001b[39m 5 275200 train loss: 0.0006024 valid loss: 0.0008398 P@1: 0.91462 P@3: 0.76437 P@5: 0.62815 N@3: 0.84917 N@5: 0.80524 early stop: 0\n","\u001b[32m[I 210617 22:40:35 models:110]\u001b[39m 5 300800 train loss: 0.0005998 valid loss: 0.0008393 P@1: 0.91491 P@3: 0.76452 P@5: 0.62846 N@3: 0.84934 N@5: 0.80554 early stop: 0\n","\u001b[32m[I 210617 22:43:56 models:110]\u001b[39m 5 326400 train loss: 0.0006079 valid loss: 0.0008387 P@1: 0.91488 P@3: 0.76474 P@5: 0.62883 N@3: 0.84953 N@5: 0.80585 early stop: 0\n","\u001b[32m[I 210617 22:47:18 models:110]\u001b[39m 5 352000 train loss: 0.0006045 valid loss: 0.0008384 P@1: 0.91502 P@3: 0.76505 P@5: 0.62900 N@3: 0.84980 N@5: 0.80602 early stop: 0\n","\u001b[32m[I 210617 22:50:39 models:110]\u001b[39m 5 377600 train loss: 0.0006060 valid loss: 0.0008379 P@1: 0.91503 P@3: 0.76535 P@5: 0.62945 N@3: 0.85002 N@5: 0.80639 early stop: 0\n","\u001b[32m[I 210617 22:54:02 models:110]\u001b[39m 5 403200 train loss: 0.0006094 valid loss: 0.0008371 P@1: 0.91520 P@3: 0.76560 P@5: 0.63002 N@3: 0.85024 N@5: 0.80683 early stop: 0\n","\u001b[32m[I 210617 22:57:24 models:110]\u001b[39m 5 428800 train loss: 0.0006118 valid loss: 0.0008362 P@1: 0.91537 P@3: 0.76583 P@5: 0.63026 N@3: 0.85045 N@5: 0.80707 early stop: 0\n","\u001b[32m[I 210617 23:00:46 models:110]\u001b[39m 5 454400 train loss: 0.0006081 valid loss: 0.0008354 P@1: 0.91559 P@3: 0.76616 P@5: 0.63061 N@3: 0.85079 N@5: 0.80743 early stop: 0\n","\u001b[32m[I 210617 23:04:10 models:110]\u001b[39m 5 480000 train loss: 0.0006091 valid loss: 0.0008345 P@1: 0.91559 P@3: 0.76656 P@5: 0.63087 N@3: 0.85109 N@5: 0.80769 early stop: 0\n","\u001b[32m[I 210617 23:07:31 models:110]\u001b[39m 5 505600 train loss: 0.0006183 valid loss: 0.0008337 P@1: 0.91563 P@3: 0.76692 P@5: 0.63123 N@3: 0.85140 N@5: 0.80801 early stop: 0\n","\u001b[32m[I 210617 23:10:52 models:110]\u001b[39m 5 531200 train loss: 0.0006118 valid loss: 0.0008329 P@1: 0.91564 P@3: 0.76711 P@5: 0.63157 N@3: 0.85157 N@5: 0.80830 early stop: 0\n","\u001b[32m[I 210617 23:14:14 models:110]\u001b[39m 5 556800 train loss: 0.0006150 valid loss: 0.0008319 P@1: 0.91596 P@3: 0.76737 P@5: 0.63186 N@3: 0.85181 N@5: 0.80861 early stop: 0\n","\u001b[32m[I 210617 23:17:37 models:110]\u001b[39m 6 17920 train loss: 0.0005040 valid loss: 0.0008320 P@1: 0.91611 P@3: 0.76760 P@5: 0.63208 N@3: 0.85201 N@5: 0.80882 early stop: 0\n","\u001b[32m[I 210617 23:20:58 models:110]\u001b[39m 6 43520 train loss: 0.0004629 valid loss: 0.0008323 P@1: 0.91620 P@3: 0.76774 P@5: 0.63223 N@3: 0.85211 N@5: 0.80895 early stop: 0\n","\u001b[32m[I 210617 23:24:19 models:110]\u001b[39m 6 69120 train loss: 0.0004694 valid loss: 0.0008326 P@1: 0.91621 P@3: 0.76786 P@5: 0.63253 N@3: 0.85222 N@5: 0.80919 early stop: 0\n","\u001b[32m[I 210617 23:27:40 models:110]\u001b[39m 6 94720 train loss: 0.0004745 valid loss: 0.0008330 P@1: 0.91617 P@3: 0.76804 P@5: 0.63270 N@3: 0.85232 N@5: 0.80927 early stop: 0\n","\u001b[32m[I 210617 23:31:01 models:110]\u001b[39m 6 120320 train loss: 0.0004792 valid loss: 0.0008335 P@1: 0.91610 P@3: 0.76823 P@5: 0.63292 N@3: 0.85243 N@5: 0.80942 early stop: 0\n","\u001b[32m[I 210617 23:34:20 models:110]\u001b[39m 6 145920 train loss: 0.0004814 valid loss: 0.0008339 P@1: 0.91604 P@3: 0.76834 P@5: 0.63310 N@3: 0.85250 N@5: 0.80955 early stop: 0\n","\u001b[32m[I 210617 23:37:39 models:110]\u001b[39m 6 171520 train loss: 0.0004856 valid loss: 0.0008342 P@1: 0.91620 P@3: 0.76840 P@5: 0.63337 N@3: 0.85255 N@5: 0.80977 early stop: 0\n","\u001b[32m[I 210617 23:40:59 models:110]\u001b[39m 6 197120 train loss: 0.0004848 valid loss: 0.0008347 P@1: 0.91625 P@3: 0.76860 P@5: 0.63345 N@3: 0.85274 N@5: 0.80984 early stop: 0\n","\u001b[32m[I 210617 23:44:17 models:110]\u001b[39m 6 222720 train loss: 0.0004948 valid loss: 0.0008350 P@1: 0.91608 P@3: 0.76875 P@5: 0.63368 N@3: 0.85282 N@5: 0.81000 early stop: 0\n","\u001b[32m[I 210617 23:47:38 models:110]\u001b[39m 6 248320 train loss: 0.0004913 valid loss: 0.0008352 P@1: 0.91622 P@3: 0.76884 P@5: 0.63384 N@3: 0.85295 N@5: 0.81015 early stop: 0\n","\u001b[32m[I 210617 23:51:01 models:110]\u001b[39m 6 273920 train loss: 0.0004954 valid loss: 0.0008354 P@1: 0.91624 P@3: 0.76904 P@5: 0.63390 N@3: 0.85312 N@5: 0.81025 early stop: 0\n","\u001b[32m[I 210617 23:54:22 models:110]\u001b[39m 6 299520 train loss: 0.0005021 valid loss: 0.0008356 P@1: 0.91638 P@3: 0.76928 P@5: 0.63407 N@3: 0.85332 N@5: 0.81040 early stop: 0\n","\u001b[32m[I 210617 23:57:42 models:110]\u001b[39m 6 325120 train loss: 0.0005009 valid loss: 0.0008358 P@1: 0.91632 P@3: 0.76936 P@5: 0.63423 N@3: 0.85339 N@5: 0.81057 early stop: 0\n","\u001b[32m[I 210618 00:01:02 models:110]\u001b[39m 6 350720 train loss: 0.0005023 valid loss: 0.0008359 P@1: 0.91630 P@3: 0.76941 P@5: 0.63434 N@3: 0.85340 N@5: 0.81063 early stop: 0\n","\u001b[32m[I 210618 00:04:23 models:110]\u001b[39m 6 376320 train loss: 0.0005116 valid loss: 0.0008360 P@1: 0.91634 P@3: 0.76944 P@5: 0.63443 N@3: 0.85343 N@5: 0.81073 early stop: 0\n","\u001b[32m[I 210618 00:07:44 models:110]\u001b[39m 6 401920 train loss: 0.0005106 valid loss: 0.0008362 P@1: 0.91642 P@3: 0.76941 P@5: 0.63457 N@3: 0.85345 N@5: 0.81086 early stop: 0\n","\u001b[32m[I 210618 00:11:06 models:110]\u001b[39m 6 427520 train loss: 0.0005120 valid loss: 0.0008363 P@1: 0.91652 P@3: 0.76956 P@5: 0.63475 N@3: 0.85357 N@5: 0.81101 early stop: 0\n","\u001b[32m[I 210618 00:14:27 models:110]\u001b[39m 6 453120 train loss: 0.0005148 valid loss: 0.0008364 P@1: 0.91661 P@3: 0.76972 P@5: 0.63505 N@3: 0.85371 N@5: 0.81127 early stop: 0\n","\u001b[32m[I 210618 00:17:48 models:110]\u001b[39m 6 478720 train loss: 0.0005191 valid loss: 0.0008363 P@1: 0.91689 P@3: 0.76978 P@5: 0.63517 N@3: 0.85377 N@5: 0.81139 early stop: 0\n","\u001b[32m[I 210618 00:21:09 models:110]\u001b[39m 6 504320 train loss: 0.0005146 valid loss: 0.0008361 P@1: 0.91693 P@3: 0.77005 P@5: 0.63550 N@3: 0.85400 N@5: 0.81168 early stop: 0\n","\u001b[32m[I 210618 00:24:29 models:110]\u001b[39m 6 529920 train loss: 0.0005200 valid loss: 0.0008360 P@1: 0.91706 P@3: 0.77013 P@5: 0.63576 N@3: 0.85410 N@5: 0.81190 early stop: 0\n","\u001b[32m[I 210618 00:27:50 models:110]\u001b[39m 6 555520 train loss: 0.0005172 valid loss: 0.0008359 P@1: 0.91708 P@3: 0.77031 P@5: 0.63597 N@3: 0.85424 N@5: 0.81204 early stop: 0\n","\u001b[32m[I 210618 00:31:14 models:110]\u001b[39m 7 16640 train loss: 0.0004291 valid loss: 0.0008365 P@1: 0.91712 P@3: 0.77043 P@5: 0.63604 N@3: 0.85434 N@5: 0.81209 early stop: 0\n","\u001b[32m[I 210618 00:34:37 models:110]\u001b[39m 7 42240 train loss: 0.0003800 valid loss: 0.0008370 P@1: 0.91712 P@3: 0.77049 P@5: 0.63606 N@3: 0.85438 N@5: 0.81210 early stop: 0\n","\u001b[32m[I 210618 00:38:01 models:110]\u001b[39m 7 67840 train loss: 0.0003812 valid loss: 0.0008378 P@1: 0.91706 P@3: 0.77059 P@5: 0.63622 N@3: 0.85445 N@5: 0.81221 early stop: 0\n","\u001b[32m[I 210618 00:41:22 models:110]\u001b[39m 7 93440 train loss: 0.0003912 valid loss: 0.0008385 P@1: 0.91709 P@3: 0.77080 P@5: 0.63633 N@3: 0.85459 N@5: 0.81232 early stop: 0\n","\u001b[32m[I 210618 00:44:41 models:110]\u001b[39m 7 119040 train loss: 0.0003994 valid loss: 0.0008392 P@1: 0.91705 P@3: 0.77078 P@5: 0.63651 N@3: 0.85457 N@5: 0.81245 early stop: 0\n","\u001b[32m[I 210618 00:47:58 models:110]\u001b[39m 7 144640 train loss: 0.0004050 valid loss: 0.0008398 P@1: 0.91720 P@3: 0.77095 P@5: 0.63658 N@3: 0.85476 N@5: 0.81258 early stop: 0\n","\u001b[32m[I 210618 00:51:17 models:110]\u001b[39m 7 170240 train loss: 0.0004054 valid loss: 0.0008404 P@1: 0.91712 P@3: 0.77103 P@5: 0.63675 N@3: 0.85481 N@5: 0.81268 early stop: 0\n","\u001b[32m[I 210618 00:54:36 models:110]\u001b[39m 7 195840 train loss: 0.0004108 valid loss: 0.0008411 P@1: 0.91686 P@3: 0.77112 P@5: 0.63683 N@3: 0.85483 N@5: 0.81270 early stop: 0\n","\u001b[32m[I 210618 00:57:54 models:110]\u001b[39m 7 221440 train loss: 0.0004130 valid loss: 0.0008416 P@1: 0.91689 P@3: 0.77118 P@5: 0.63683 N@3: 0.85490 N@5: 0.81268 early stop: 1\n","\u001b[32m[I 210618 01:01:12 models:110]\u001b[39m 7 247040 train loss: 0.0004155 valid loss: 0.0008422 P@1: 0.91689 P@3: 0.77117 P@5: 0.63696 N@3: 0.85490 N@5: 0.81278 early stop: 0\n","\u001b[32m[I 210618 01:04:31 models:110]\u001b[39m 7 272640 train loss: 0.0004189 valid loss: 0.0008428 P@1: 0.91674 P@3: 0.77132 P@5: 0.63709 N@3: 0.85495 N@5: 0.81284 early stop: 0\n","\u001b[32m[I 210618 01:07:49 models:110]\u001b[39m 7 298240 train loss: 0.0004203 valid loss: 0.0008435 P@1: 0.91669 P@3: 0.77130 P@5: 0.63710 N@3: 0.85494 N@5: 0.81285 early stop: 0\n","\u001b[32m[I 210618 01:11:08 models:110]\u001b[39m 7 323840 train loss: 0.0004232 valid loss: 0.0008441 P@1: 0.91674 P@3: 0.77139 P@5: 0.63721 N@3: 0.85502 N@5: 0.81296 early stop: 0\n","\u001b[32m[I 210618 01:14:27 models:110]\u001b[39m 7 349440 train loss: 0.0004298 valid loss: 0.0008447 P@1: 0.91679 P@3: 0.77139 P@5: 0.63733 N@3: 0.85501 N@5: 0.81302 early stop: 0\n","\u001b[32m[I 210618 01:17:46 models:110]\u001b[39m 7 375040 train loss: 0.0004293 valid loss: 0.0008452 P@1: 0.91674 P@3: 0.77155 P@5: 0.63744 N@3: 0.85512 N@5: 0.81311 early stop: 0\n","\u001b[32m[I 210618 01:21:06 models:110]\u001b[39m 7 400640 train loss: 0.0004313 valid loss: 0.0008456 P@1: 0.91682 P@3: 0.77155 P@5: 0.63760 N@3: 0.85517 N@5: 0.81328 early stop: 0\n","\u001b[32m[I 210618 01:24:25 models:110]\u001b[39m 7 426240 train loss: 0.0004309 valid loss: 0.0008460 P@1: 0.91689 P@3: 0.77160 P@5: 0.63767 N@3: 0.85522 N@5: 0.81335 early stop: 0\n","\u001b[32m[I 210618 01:27:44 models:110]\u001b[39m 7 451840 train loss: 0.0004411 valid loss: 0.0008464 P@1: 0.91685 P@3: 0.77165 P@5: 0.63777 N@3: 0.85526 N@5: 0.81342 early stop: 0\n","\u001b[32m[I 210618 01:31:01 models:110]\u001b[39m 7 477440 train loss: 0.0004382 valid loss: 0.0008469 P@1: 0.91669 P@3: 0.77169 P@5: 0.63784 N@3: 0.85524 N@5: 0.81346 early stop: 0\n","\u001b[32m[I 210618 01:34:19 models:110]\u001b[39m 7 503040 train loss: 0.0004409 valid loss: 0.0008471 P@1: 0.91668 P@3: 0.77170 P@5: 0.63801 N@3: 0.85527 N@5: 0.81360 early stop: 0\n","\u001b[32m[I 210618 01:37:37 models:110]\u001b[39m 7 528640 train loss: 0.0004435 valid loss: 0.0008474 P@1: 0.91675 P@3: 0.77188 P@5: 0.63813 N@3: 0.85540 N@5: 0.81370 early stop: 0\n","\u001b[32m[I 210618 01:40:56 models:110]\u001b[39m 7 554240 train loss: 0.0004443 valid loss: 0.0008477 P@1: 0.91669 P@3: 0.77193 P@5: 0.63815 N@3: 0.85542 N@5: 0.81371 early stop: 0\n","\u001b[32m[I 210618 01:44:18 models:110]\u001b[39m 8 15360 train loss: 0.0003721 valid loss: 0.0008486 P@1: 0.91662 P@3: 0.77195 P@5: 0.63823 N@3: 0.85543 N@5: 0.81375 early stop: 0\n","\u001b[32m[I 210618 01:47:36 models:110]\u001b[39m 8 40960 train loss: 0.0003174 valid loss: 0.0008494 P@1: 0.91651 P@3: 0.77195 P@5: 0.63834 N@3: 0.85541 N@5: 0.81380 early stop: 0\n","\u001b[32m[I 210618 01:50:55 models:110]\u001b[39m 8 66560 train loss: 0.0003286 valid loss: 0.0008503 P@1: 0.91651 P@3: 0.77205 P@5: 0.63840 N@3: 0.85548 N@5: 0.81383 early stop: 0\n","\u001b[32m[I 210618 01:54:14 models:110]\u001b[39m 8 92160 train loss: 0.0003289 valid loss: 0.0008513 P@1: 0.91654 P@3: 0.77207 P@5: 0.63855 N@3: 0.85549 N@5: 0.81392 early stop: 0\n","\u001b[32m[I 210618 01:57:34 models:110]\u001b[39m 8 117760 train loss: 0.0003364 valid loss: 0.0008522 P@1: 0.91659 P@3: 0.77214 P@5: 0.63858 N@3: 0.85557 N@5: 0.81397 early stop: 0\n","\u001b[32m[I 210618 02:00:53 models:110]\u001b[39m 8 143360 train loss: 0.0003436 valid loss: 0.0008531 P@1: 0.91655 P@3: 0.77223 P@5: 0.63872 N@3: 0.85564 N@5: 0.81408 early stop: 0\n","\u001b[32m[I 210618 02:04:11 models:110]\u001b[39m 8 168960 train loss: 0.0003458 valid loss: 0.0008538 P@1: 0.91654 P@3: 0.77226 P@5: 0.63883 N@3: 0.85566 N@5: 0.81417 early stop: 0\n","\u001b[32m[I 210618 02:07:31 models:110]\u001b[39m 8 194560 train loss: 0.0003432 valid loss: 0.0008546 P@1: 0.91662 P@3: 0.77218 P@5: 0.63888 N@3: 0.85561 N@5: 0.81422 early stop: 0\n","\u001b[32m[I 210618 02:10:47 models:110]\u001b[39m 8 220160 train loss: 0.0003516 valid loss: 0.0008553 P@1: 0.91662 P@3: 0.77222 P@5: 0.63885 N@3: 0.85561 N@5: 0.81418 early stop: 1\n","\u001b[32m[I 210618 02:14:03 models:110]\u001b[39m 8 245760 train loss: 0.0003523 valid loss: 0.0008561 P@1: 0.91655 P@3: 0.77222 P@5: 0.63879 N@3: 0.85559 N@5: 0.81411 early stop: 2\n","\u001b[32m[I 210618 02:17:21 models:110]\u001b[39m 8 271360 train loss: 0.0003596 valid loss: 0.0008569 P@1: 0.91647 P@3: 0.77218 P@5: 0.63880 N@3: 0.85554 N@5: 0.81409 early stop: 3\n","\u001b[32m[I 210618 02:20:37 models:110]\u001b[39m 8 296960 train loss: 0.0003582 valid loss: 0.0008577 P@1: 0.91645 P@3: 0.77228 P@5: 0.63886 N@3: 0.85562 N@5: 0.81415 early stop: 4\n","\u001b[32m[I 210618 02:23:53 models:110]\u001b[39m 8 322560 train loss: 0.0003640 valid loss: 0.0008585 P@1: 0.91655 P@3: 0.77242 P@5: 0.63887 N@3: 0.85575 N@5: 0.81419 early stop: 5\n","\u001b[32m[I 210618 02:27:12 models:110]\u001b[39m 8 348160 train loss: 0.0003660 valid loss: 0.0008591 P@1: 0.91652 P@3: 0.77253 P@5: 0.63892 N@3: 0.85583 N@5: 0.81424 early stop: 0\n","\u001b[32m[I 210618 02:30:29 models:110]\u001b[39m 8 373760 train loss: 0.0003670 valid loss: 0.0008597 P@1: 0.91652 P@3: 0.77249 P@5: 0.63902 N@3: 0.85581 N@5: 0.81431 early stop: 0\n","\u001b[32m[I 210618 02:33:48 models:110]\u001b[39m 8 399360 train loss: 0.0003705 valid loss: 0.0008604 P@1: 0.91645 P@3: 0.77263 P@5: 0.63908 N@3: 0.85591 N@5: 0.81434 early stop: 0\n","\u001b[32m[I 210618 02:37:07 models:110]\u001b[39m 8 424960 train loss: 0.0003744 valid loss: 0.0008611 P@1: 0.91638 P@3: 0.77256 P@5: 0.63918 N@3: 0.85584 N@5: 0.81441 early stop: 0\n","\u001b[32m[I 210618 02:40:25 models:110]\u001b[39m 8 450560 train loss: 0.0003781 valid loss: 0.0008617 P@1: 0.91639 P@3: 0.77260 P@5: 0.63919 N@3: 0.85589 N@5: 0.81444 early stop: 0\n","\u001b[32m[I 210618 02:43:43 models:110]\u001b[39m 8 476160 train loss: 0.0003797 valid loss: 0.0008623 P@1: 0.91625 P@3: 0.77261 P@5: 0.63918 N@3: 0.85585 N@5: 0.81440 early stop: 1\n","\u001b[32m[I 210618 02:46:59 models:110]\u001b[39m 8 501760 train loss: 0.0003808 valid loss: 0.0008629 P@1: 0.91625 P@3: 0.77261 P@5: 0.63923 N@3: 0.85586 N@5: 0.81443 early stop: 2\n","\u001b[32m[I 210618 02:50:15 models:110]\u001b[39m 8 527360 train loss: 0.0003855 valid loss: 0.0008634 P@1: 0.91624 P@3: 0.77262 P@5: 0.63927 N@3: 0.85589 N@5: 0.81449 early stop: 0\n","\u001b[32m[I 210618 02:53:33 models:110]\u001b[39m 8 552960 train loss: 0.0003866 valid loss: 0.0008640 P@1: 0.91621 P@3: 0.77259 P@5: 0.63931 N@3: 0.85587 N@5: 0.81451 early stop: 0\n","\u001b[32m[I 210618 02:56:53 models:110]\u001b[39m 9 14080 train loss: 0.0003286 valid loss: 0.0008648 P@1: 0.91627 P@3: 0.77266 P@5: 0.63947 N@3: 0.85591 N@5: 0.81464 early stop: 0\n","\u001b[32m[I 210618 03:00:09 models:110]\u001b[39m 9 39680 train loss: 0.0002730 valid loss: 0.0008658 P@1: 0.91627 P@3: 0.77263 P@5: 0.63953 N@3: 0.85590 N@5: 0.81470 early stop: 0\n","\u001b[32m[I 210618 03:03:26 models:110]\u001b[39m 9 65280 train loss: 0.0002801 valid loss: 0.0008670 P@1: 0.91625 P@3: 0.77262 P@5: 0.63951 N@3: 0.85589 N@5: 0.81468 early stop: 1\n","\u001b[32m[I 210618 03:06:41 models:110]\u001b[39m 9 90880 train loss: 0.0002865 valid loss: 0.0008680 P@1: 0.91631 P@3: 0.77259 P@5: 0.63958 N@3: 0.85588 N@5: 0.81471 early stop: 0\n","\u001b[32m[I 210618 03:09:58 models:110]\u001b[39m 9 116480 train loss: 0.0002899 valid loss: 0.0008689 P@1: 0.91630 P@3: 0.77263 P@5: 0.63965 N@3: 0.85590 N@5: 0.81475 early stop: 0\n","\u001b[32m[I 210618 03:13:15 models:110]\u001b[39m 9 142080 train loss: 0.0002951 valid loss: 0.0008700 P@1: 0.91618 P@3: 0.77266 P@5: 0.63960 N@3: 0.85590 N@5: 0.81471 early stop: 1\n","\u001b[32m[I 210618 03:16:31 models:110]\u001b[39m 9 167680 train loss: 0.0002942 valid loss: 0.0008710 P@1: 0.91622 P@3: 0.77266 P@5: 0.63970 N@3: 0.85590 N@5: 0.81478 early stop: 0\n","\u001b[32m[I 210618 03:19:51 models:110]\u001b[39m 9 193280 train loss: 0.0003016 valid loss: 0.0008720 P@1: 0.91615 P@3: 0.77268 P@5: 0.63975 N@3: 0.85590 N@5: 0.81482 early stop: 0\n","\u001b[32m[I 210618 03:23:08 models:110]\u001b[39m 9 218880 train loss: 0.0003021 valid loss: 0.0008731 P@1: 0.91608 P@3: 0.77273 P@5: 0.63977 N@3: 0.85593 N@5: 0.81484 early stop: 0\n","\u001b[32m[I 210618 03:26:26 models:110]\u001b[39m 9 244480 train loss: 0.0003085 valid loss: 0.0008740 P@1: 0.91604 P@3: 0.77283 P@5: 0.63985 N@3: 0.85598 N@5: 0.81488 early stop: 0\n","\u001b[32m[I 210618 03:29:45 models:110]\u001b[39m 9 270080 train loss: 0.0003107 valid loss: 0.0008750 P@1: 0.91615 P@3: 0.77284 P@5: 0.63989 N@3: 0.85599 N@5: 0.81491 early stop: 0\n","\u001b[32m[I 210618 03:33:06 models:110]\u001b[39m 9 295680 train loss: 0.0003124 valid loss: 0.0008758 P@1: 0.91625 P@3: 0.77287 P@5: 0.63996 N@3: 0.85604 N@5: 0.81500 early stop: 0\n","\u001b[32m[I 210618 03:36:24 models:110]\u001b[39m 9 321280 train loss: 0.0003144 valid loss: 0.0008768 P@1: 0.91622 P@3: 0.77291 P@5: 0.63998 N@3: 0.85605 N@5: 0.81499 early stop: 1\n","\u001b[32m[I 210618 03:39:40 models:110]\u001b[39m 9 346880 train loss: 0.0003190 valid loss: 0.0008777 P@1: 0.91620 P@3: 0.77302 P@5: 0.64010 N@3: 0.85611 N@5: 0.81509 early stop: 0\n","\u001b[32m[I 210618 03:42:59 models:110]\u001b[39m 9 372480 train loss: 0.0003228 valid loss: 0.0008786 P@1: 0.91632 P@3: 0.77313 P@5: 0.64019 N@3: 0.85624 N@5: 0.81520 early stop: 0\n","\u001b[32m[I 210618 03:46:17 models:110]\u001b[39m 9 398080 train loss: 0.0003219 valid loss: 0.0008794 P@1: 0.91624 P@3: 0.77319 P@5: 0.64020 N@3: 0.85628 N@5: 0.81523 early stop: 0\n","\u001b[32m[I 210618 03:49:38 models:110]\u001b[39m 9 423680 train loss: 0.0003261 valid loss: 0.0008803 P@1: 0.91620 P@3: 0.77325 P@5: 0.64027 N@3: 0.85631 N@5: 0.81525 early stop: 0\n","\u001b[32m[I 210618 03:52:59 models:110]\u001b[39m 9 449280 train loss: 0.0003291 valid loss: 0.0008811 P@1: 0.91611 P@3: 0.77329 P@5: 0.64038 N@3: 0.85634 N@5: 0.81532 early stop: 0\n","\u001b[32m[I 210618 03:56:20 models:110]\u001b[39m 9 474880 train loss: 0.0003297 valid loss: 0.0008819 P@1: 0.91613 P@3: 0.77319 P@5: 0.64035 N@3: 0.85626 N@5: 0.81530 early stop: 1\n","\u001b[32m[I 210618 03:59:39 models:110]\u001b[39m 9 500480 train loss: 0.0003328 valid loss: 0.0008826 P@1: 0.91617 P@3: 0.77321 P@5: 0.64040 N@3: 0.85627 N@5: 0.81532 early stop: 0\n","\u001b[32m[I 210618 04:02:57 models:110]\u001b[39m 9 526080 train loss: 0.0003348 valid loss: 0.0008833 P@1: 0.91611 P@3: 0.77325 P@5: 0.64041 N@3: 0.85627 N@5: 0.81531 early stop: 1\n","\u001b[32m[I 210618 04:06:15 models:110]\u001b[39m 9 551680 train loss: 0.0003400 valid loss: 0.0008840 P@1: 0.91621 P@3: 0.77330 P@5: 0.64047 N@3: 0.85634 N@5: 0.81537 early stop: 0\n","\u001b[32m[I 210618 04:09:35 models:110]\u001b[39m 10 12800 train loss: 0.0002882 valid loss: 0.0008850 P@1: 0.91625 P@3: 0.77340 P@5: 0.64051 N@3: 0.85643 N@5: 0.81543 early stop: 0\n","\u001b[32m[I 210618 04:12:54 models:110]\u001b[39m 10 38400 train loss: 0.0002400 valid loss: 0.0008861 P@1: 0.91613 P@3: 0.77336 P@5: 0.64056 N@3: 0.85634 N@5: 0.81540 early stop: 1\n","\u001b[32m[I 210618 04:16:11 models:110]\u001b[39m 10 64000 train loss: 0.0002460 valid loss: 0.0008872 P@1: 0.91604 P@3: 0.77340 P@5: 0.64053 N@3: 0.85636 N@5: 0.81538 early stop: 2\n","\u001b[32m[I 210618 04:19:28 models:110]\u001b[39m 10 89600 train loss: 0.0002503 valid loss: 0.0008884 P@1: 0.91603 P@3: 0.77334 P@5: 0.64052 N@3: 0.85632 N@5: 0.81538 early stop: 3\n","\u001b[32m[I 210618 04:22:45 models:110]\u001b[39m 10 115200 train loss: 0.0002527 valid loss: 0.0008895 P@1: 0.91603 P@3: 0.77335 P@5: 0.64054 N@3: 0.85634 N@5: 0.81541 early stop: 4\n","\u001b[32m[I 210618 04:26:01 models:110]\u001b[39m 10 140800 train loss: 0.0002551 valid loss: 0.0008906 P@1: 0.91596 P@3: 0.77335 P@5: 0.64054 N@3: 0.85629 N@5: 0.81536 early stop: 5\n","\u001b[32m[I 210618 04:29:15 models:110]\u001b[39m 10 166400 train loss: 0.0002585 valid loss: 0.0008917 P@1: 0.91594 P@3: 0.77335 P@5: 0.64054 N@3: 0.85628 N@5: 0.81536 early stop: 6\n","\u001b[32m[I 210618 04:32:31 models:110]\u001b[39m 10 192000 train loss: 0.0002629 valid loss: 0.0008928 P@1: 0.91588 P@3: 0.77337 P@5: 0.64054 N@3: 0.85629 N@5: 0.81535 early stop: 7\n","\u001b[32m[I 210618 04:35:47 models:110]\u001b[39m 10 217600 train loss: 0.0002662 valid loss: 0.0008939 P@1: 0.91588 P@3: 0.77333 P@5: 0.64053 N@3: 0.85625 N@5: 0.81533 early stop: 8\n","\u001b[32m[I 210618 04:39:02 models:110]\u001b[39m 10 243200 train loss: 0.0002673 valid loss: 0.0008950 P@1: 0.91586 P@3: 0.77329 P@5: 0.64056 N@3: 0.85620 N@5: 0.81534 early stop: 9\n","\u001b[32m[I 210618 04:42:18 models:110]\u001b[39m 10 268800 train loss: 0.0002713 valid loss: 0.0008960 P@1: 0.91574 P@3: 0.77322 P@5: 0.64063 N@3: 0.85613 N@5: 0.81536 early stop: 10\n","\u001b[32m[I 210618 04:45:34 models:110]\u001b[39m 10 294400 train loss: 0.0002742 valid loss: 0.0008970 P@1: 0.91570 P@3: 0.77325 P@5: 0.64064 N@3: 0.85615 N@5: 0.81537 early stop: 11\n","\u001b[32m[I 210618 04:48:49 models:110]\u001b[39m 10 320000 train loss: 0.0002811 valid loss: 0.0008982 P@1: 0.91571 P@3: 0.77322 P@5: 0.64055 N@3: 0.85611 N@5: 0.81529 early stop: 12\n","\u001b[32m[I 210618 04:52:04 models:110]\u001b[39m 10 345600 train loss: 0.0002788 valid loss: 0.0008992 P@1: 0.91570 P@3: 0.77319 P@5: 0.64062 N@3: 0.85609 N@5: 0.81533 early stop: 13\n","\u001b[32m[I 210618 04:55:20 models:110]\u001b[39m 10 371200 train loss: 0.0002844 valid loss: 0.0009002 P@1: 0.91567 P@3: 0.77323 P@5: 0.64068 N@3: 0.85609 N@5: 0.81535 early stop: 14\n","\u001b[32m[I 210618 04:58:38 models:110]\u001b[39m 10 396800 train loss: 0.0002839 valid loss: 0.0009012 P@1: 0.91577 P@3: 0.77319 P@5: 0.64069 N@3: 0.85609 N@5: 0.81537 early stop: 15\n","\u001b[32m[I 210618 05:01:54 models:110]\u001b[39m 10 422400 train loss: 0.0002879 valid loss: 0.0009021 P@1: 0.91574 P@3: 0.77321 P@5: 0.64075 N@3: 0.85610 N@5: 0.81542 early stop: 16\n","\u001b[32m[I 210618 05:05:11 models:110]\u001b[39m 10 448000 train loss: 0.0002850 valid loss: 0.0009030 P@1: 0.91577 P@3: 0.77325 P@5: 0.64087 N@3: 0.85613 N@5: 0.81551 early stop: 0\n","\u001b[32m[I 210618 05:08:28 models:110]\u001b[39m 10 473600 train loss: 0.0002942 valid loss: 0.0009039 P@1: 0.91587 P@3: 0.77330 P@5: 0.64085 N@3: 0.85616 N@5: 0.81548 early stop: 1\n","\u001b[32m[I 210618 05:11:44 models:110]\u001b[39m 10 499200 train loss: 0.0002922 valid loss: 0.0009049 P@1: 0.91573 P@3: 0.77323 P@5: 0.64082 N@3: 0.85609 N@5: 0.81543 early stop: 2\n","\u001b[32m[I 210618 05:14:59 models:110]\u001b[39m 10 524800 train loss: 0.0002951 valid loss: 0.0009058 P@1: 0.91559 P@3: 0.77325 P@5: 0.64083 N@3: 0.85607 N@5: 0.81543 early stop: 3\n","\u001b[32m[I 210618 05:18:14 models:110]\u001b[39m 10 550400 train loss: 0.0002992 valid loss: 0.0009066 P@1: 0.91562 P@3: 0.77323 P@5: 0.64087 N@3: 0.85604 N@5: 0.81543 early stop: 4\n","\u001b[32m[I 210618 05:21:30 models:110]\u001b[39m 11 11520 train loss: 0.0002634 valid loss: 0.0009077 P@1: 0.91560 P@3: 0.77317 P@5: 0.64093 N@3: 0.85601 N@5: 0.81549 early stop: 5\n","\u001b[32m[I 210618 05:24:47 models:110]\u001b[39m 11 37120 train loss: 0.0002148 valid loss: 0.0009089 P@1: 0.91567 P@3: 0.77319 P@5: 0.64094 N@3: 0.85602 N@5: 0.81549 early stop: 6\n","\u001b[32m[I 210618 05:28:07 models:110]\u001b[39m 11 62720 train loss: 0.0002138 valid loss: 0.0009101 P@1: 0.91584 P@3: 0.77312 P@5: 0.64094 N@3: 0.85600 N@5: 0.81552 early stop: 0\n","\u001b[32m[I 210618 05:31:25 models:110]\u001b[39m 11 88320 train loss: 0.0002180 valid loss: 0.0009112 P@1: 0.91576 P@3: 0.77315 P@5: 0.64101 N@3: 0.85602 N@5: 0.81555 early stop: 0\n","\u001b[32m[I 210618 05:34:44 models:110]\u001b[39m 11 113920 train loss: 0.0002237 valid loss: 0.0009124 P@1: 0.91573 P@3: 0.77319 P@5: 0.64108 N@3: 0.85603 N@5: 0.81560 early stop: 0\n","\u001b[32m[I 210618 05:38:01 models:110]\u001b[39m 11 139520 train loss: 0.0002240 valid loss: 0.0009136 P@1: 0.91570 P@3: 0.77319 P@5: 0.64109 N@3: 0.85601 N@5: 0.81558 early stop: 1\n","\u001b[32m[I 210618 05:41:14 models:110]\u001b[39m 11 165120 train loss: 0.0002317 valid loss: 0.0009147 P@1: 0.91570 P@3: 0.77319 P@5: 0.64105 N@3: 0.85599 N@5: 0.81554 early stop: 2\n","\u001b[32m[I 210618 05:44:28 models:110]\u001b[39m 11 190720 train loss: 0.0002337 valid loss: 0.0009159 P@1: 0.91560 P@3: 0.77316 P@5: 0.64112 N@3: 0.85595 N@5: 0.81556 early stop: 3\n","\u001b[32m[I 210618 05:47:42 models:110]\u001b[39m 11 216320 train loss: 0.0002372 valid loss: 0.0009170 P@1: 0.91574 P@3: 0.77309 P@5: 0.64109 N@3: 0.85592 N@5: 0.81555 early stop: 4\n","\u001b[32m[I 210618 05:50:56 models:110]\u001b[39m 11 241920 train loss: 0.0002379 valid loss: 0.0009182 P@1: 0.91560 P@3: 0.77306 P@5: 0.64112 N@3: 0.85585 N@5: 0.81553 early stop: 5\n","\u001b[32m[I 210618 05:54:11 models:110]\u001b[39m 11 267520 train loss: 0.0002439 valid loss: 0.0009192 P@1: 0.91567 P@3: 0.77303 P@5: 0.64112 N@3: 0.85584 N@5: 0.81553 early stop: 6\n","\u001b[32m[I 210618 05:57:25 models:110]\u001b[39m 11 293120 train loss: 0.0002449 valid loss: 0.0009204 P@1: 0.91553 P@3: 0.77302 P@5: 0.64114 N@3: 0.85581 N@5: 0.81552 early stop: 7\n","\u001b[32m[I 210618 06:00:40 models:110]\u001b[39m 11 318720 train loss: 0.0002490 valid loss: 0.0009214 P@1: 0.91550 P@3: 0.77297 P@5: 0.64108 N@3: 0.85576 N@5: 0.81547 early stop: 8\n","\u001b[32m[I 210618 06:03:54 models:110]\u001b[39m 11 344320 train loss: 0.0002502 valid loss: 0.0009224 P@1: 0.91545 P@3: 0.77288 P@5: 0.64114 N@3: 0.85569 N@5: 0.81549 early stop: 9\n","\u001b[32m[I 210618 06:07:08 models:110]\u001b[39m 11 369920 train loss: 0.0002489 valid loss: 0.0009235 P@1: 0.91547 P@3: 0.77287 P@5: 0.64116 N@3: 0.85570 N@5: 0.81551 early stop: 10\n","\u001b[32m[I 210618 06:10:22 models:110]\u001b[39m 11 395520 train loss: 0.0002535 valid loss: 0.0009245 P@1: 0.91547 P@3: 0.77289 P@5: 0.64116 N@3: 0.85569 N@5: 0.81550 early stop: 11\n","\u001b[32m[I 210618 06:13:36 models:110]\u001b[39m 11 421120 train loss: 0.0002548 valid loss: 0.0009254 P@1: 0.91545 P@3: 0.77285 P@5: 0.64116 N@3: 0.85564 N@5: 0.81550 early stop: 12\n","\u001b[32m[I 210618 06:16:50 models:110]\u001b[39m 11 446720 train loss: 0.0002584 valid loss: 0.0009264 P@1: 0.91537 P@3: 0.77282 P@5: 0.64117 N@3: 0.85561 N@5: 0.81549 early stop: 13\n","\u001b[32m[I 210618 06:20:05 models:110]\u001b[39m 11 472320 train loss: 0.0002642 valid loss: 0.0009273 P@1: 0.91546 P@3: 0.77285 P@5: 0.64120 N@3: 0.85565 N@5: 0.81552 early stop: 14\n","\u001b[32m[I 210618 06:23:19 models:110]\u001b[39m 11 497920 train loss: 0.0002593 valid loss: 0.0009282 P@1: 0.91543 P@3: 0.77285 P@5: 0.64119 N@3: 0.85564 N@5: 0.81550 early stop: 15\n","\u001b[32m[I 210618 06:26:37 models:110]\u001b[39m 11 523520 train loss: 0.0002641 valid loss: 0.0009291 P@1: 0.91542 P@3: 0.77284 P@5: 0.64123 N@3: 0.85563 N@5: 0.81554 early stop: 16\n","\u001b[32m[I 210618 06:29:53 models:110]\u001b[39m 11 549120 train loss: 0.0002661 valid loss: 0.0009301 P@1: 0.91539 P@3: 0.77283 P@5: 0.64128 N@3: 0.85562 N@5: 0.81557 early stop: 17\n","\u001b[32m[I 210618 06:33:11 models:110]\u001b[39m 12 10240 train loss: 0.0002382 valid loss: 0.0009312 P@1: 0.91535 P@3: 0.77287 P@5: 0.64129 N@3: 0.85563 N@5: 0.81557 early stop: 18\n","\u001b[32m[I 210618 06:36:28 models:110]\u001b[39m 12 35840 train loss: 0.0001891 valid loss: 0.0009323 P@1: 0.91539 P@3: 0.77285 P@5: 0.64133 N@3: 0.85564 N@5: 0.81559 early stop: 19\n","\u001b[32m[I 210618 06:39:42 models:110]\u001b[39m 12 61440 train loss: 0.0001937 valid loss: 0.0009334 P@1: 0.91540 P@3: 0.77285 P@5: 0.64131 N@3: 0.85563 N@5: 0.81558 early stop: 20\n","\u001b[32m[I 210618 06:43:00 models:110]\u001b[39m 12 87040 train loss: 0.0001939 valid loss: 0.0009347 P@1: 0.91554 P@3: 0.77286 P@5: 0.64133 N@3: 0.85567 N@5: 0.81562 early stop: 0\n","\u001b[32m[I 210618 06:46:18 models:110]\u001b[39m 12 112640 train loss: 0.0002008 valid loss: 0.0009359 P@1: 0.91545 P@3: 0.77287 P@5: 0.64132 N@3: 0.85566 N@5: 0.81559 early stop: 1\n","\u001b[32m[I 210618 06:49:35 models:110]\u001b[39m 12 138240 train loss: 0.0002039 valid loss: 0.0009370 P@1: 0.91547 P@3: 0.77281 P@5: 0.64130 N@3: 0.85562 N@5: 0.81557 early stop: 2\n","\u001b[32m[I 210618 06:52:53 models:110]\u001b[39m 12 163840 train loss: 0.0002051 valid loss: 0.0009382 P@1: 0.91563 P@3: 0.77280 P@5: 0.64130 N@3: 0.85564 N@5: 0.81559 early stop: 3\n","\u001b[32m[I 210618 06:56:10 models:110]\u001b[39m 12 189440 train loss: 0.0002087 valid loss: 0.0009394 P@1: 0.91557 P@3: 0.77278 P@5: 0.64129 N@3: 0.85560 N@5: 0.81554 early stop: 4\n","\u001b[32m[I 210618 06:59:30 models:110]\u001b[39m 12 215040 train loss: 0.0002097 valid loss: 0.0009405 P@1: 0.91557 P@3: 0.77278 P@5: 0.64129 N@3: 0.85559 N@5: 0.81554 early stop: 5\n","\u001b[32m[I 210618 07:02:47 models:110]\u001b[39m 12 240640 train loss: 0.0002147 valid loss: 0.0009417 P@1: 0.91563 P@3: 0.77276 P@5: 0.64129 N@3: 0.85559 N@5: 0.81555 early stop: 6\n","\u001b[32m[I 210618 07:06:04 models:110]\u001b[39m 12 266240 train loss: 0.0002148 valid loss: 0.0009429 P@1: 0.91557 P@3: 0.77280 P@5: 0.64131 N@3: 0.85562 N@5: 0.81556 early stop: 7\n","\u001b[32m[I 210618 07:09:20 models:110]\u001b[39m 12 291840 train loss: 0.0002177 valid loss: 0.0009441 P@1: 0.91552 P@3: 0.77279 P@5: 0.64123 N@3: 0.85559 N@5: 0.81549 early stop: 8\n","\u001b[32m[I 210618 07:12:36 models:110]\u001b[39m 12 317440 train loss: 0.0002202 valid loss: 0.0009452 P@1: 0.91550 P@3: 0.77278 P@5: 0.64128 N@3: 0.85557 N@5: 0.81550 early stop: 9\n","\u001b[32m[I 210618 07:15:53 models:110]\u001b[39m 12 343040 train loss: 0.0002239 valid loss: 0.0009463 P@1: 0.91559 P@3: 0.77277 P@5: 0.64128 N@3: 0.85558 N@5: 0.81553 early stop: 10\n","\u001b[32m[I 210618 07:19:08 models:110]\u001b[39m 12 368640 train loss: 0.0002263 valid loss: 0.0009474 P@1: 0.91566 P@3: 0.77281 P@5: 0.64126 N@3: 0.85561 N@5: 0.81552 early stop: 11\n","\u001b[32m[I 210618 07:22:24 models:110]\u001b[39m 12 394240 train loss: 0.0002290 valid loss: 0.0009484 P@1: 0.91554 P@3: 0.77290 P@5: 0.64127 N@3: 0.85566 N@5: 0.81553 early stop: 12\n","\u001b[32m[I 210618 07:25:39 models:110]\u001b[39m 12 419840 train loss: 0.0002313 valid loss: 0.0009495 P@1: 0.91559 P@3: 0.77291 P@5: 0.64128 N@3: 0.85569 N@5: 0.81555 early stop: 13\n","\u001b[32m[I 210618 07:28:55 models:110]\u001b[39m 12 445440 train loss: 0.0002345 valid loss: 0.0009506 P@1: 0.91552 P@3: 0.77291 P@5: 0.64125 N@3: 0.85568 N@5: 0.81551 early stop: 14\n","\u001b[32m[I 210618 07:32:11 models:110]\u001b[39m 12 471040 train loss: 0.0002312 valid loss: 0.0009517 P@1: 0.91547 P@3: 0.77295 P@5: 0.64124 N@3: 0.85570 N@5: 0.81551 early stop: 15\n","\u001b[32m[I 210618 07:35:26 models:110]\u001b[39m 12 496640 train loss: 0.0002367 valid loss: 0.0009527 P@1: 0.91553 P@3: 0.77297 P@5: 0.64129 N@3: 0.85572 N@5: 0.81554 early stop: 16\n","\u001b[32m[I 210618 07:38:43 models:110]\u001b[39m 12 522240 train loss: 0.0002391 valid loss: 0.0009538 P@1: 0.91549 P@3: 0.77292 P@5: 0.64132 N@3: 0.85566 N@5: 0.81554 early stop: 17\n","\u001b[32m[I 210618 07:41:59 models:110]\u001b[39m 12 547840 train loss: 0.0002406 valid loss: 0.0009547 P@1: 0.91549 P@3: 0.77289 P@5: 0.64134 N@3: 0.85563 N@5: 0.81554 early stop: 18\n","\u001b[32m[I 210618 07:45:20 models:110]\u001b[39m 13 8960 train loss: 0.0002209 valid loss: 0.0009557 P@1: 0.91562 P@3: 0.77295 P@5: 0.64139 N@3: 0.85569 N@5: 0.81559 early stop: 19\n","\u001b[32m[I 210618 07:48:38 models:110]\u001b[39m 13 34560 train loss: 0.0001721 valid loss: 0.0009569 P@1: 0.91563 P@3: 0.77284 P@5: 0.64138 N@3: 0.85562 N@5: 0.81559 early stop: 20\n","\u001b[32m[I 210618 07:51:57 models:110]\u001b[39m 13 60160 train loss: 0.0001749 valid loss: 0.0009582 P@1: 0.91564 P@3: 0.77275 P@5: 0.64141 N@3: 0.85556 N@5: 0.81559 early stop: 21\n","\u001b[32m[I 210618 07:55:19 models:110]\u001b[39m 13 85760 train loss: 0.0001785 valid loss: 0.0009593 P@1: 0.91570 P@3: 0.77270 P@5: 0.64139 N@3: 0.85554 N@5: 0.81560 early stop: 22\n","\u001b[32m[I 210618 07:58:38 models:110]\u001b[39m 13 111360 train loss: 0.0001786 valid loss: 0.0009605 P@1: 0.91574 P@3: 0.77276 P@5: 0.64144 N@3: 0.85560 N@5: 0.81566 early stop: 0\n","\u001b[32m[I 210618 08:01:56 models:110]\u001b[39m 13 136960 train loss: 0.0001828 valid loss: 0.0009617 P@1: 0.91570 P@3: 0.77279 P@5: 0.64143 N@3: 0.85559 N@5: 0.81563 early stop: 1\n","\u001b[32m[I 210618 08:05:15 models:110]\u001b[39m 13 162560 train loss: 0.0001861 valid loss: 0.0009629 P@1: 0.91574 P@3: 0.77274 P@5: 0.64145 N@3: 0.85557 N@5: 0.81563 early stop: 2\n","\u001b[32m[I 210618 08:08:34 models:110]\u001b[39m 13 188160 train loss: 0.0001886 valid loss: 0.0009640 P@1: 0.91574 P@3: 0.77277 P@5: 0.64149 N@3: 0.85559 N@5: 0.81566 early stop: 0\n","\u001b[32m[I 210618 08:11:53 models:110]\u001b[39m 13 213760 train loss: 0.0001933 valid loss: 0.0009651 P@1: 0.91567 P@3: 0.77278 P@5: 0.64151 N@3: 0.85557 N@5: 0.81566 early stop: 1\n","\u001b[32m[I 210618 08:15:11 models:110]\u001b[39m 13 239360 train loss: 0.0001952 valid loss: 0.0009662 P@1: 0.91554 P@3: 0.77279 P@5: 0.64149 N@3: 0.85555 N@5: 0.81562 early stop: 2\n","\u001b[32m[I 210618 08:18:28 models:110]\u001b[39m 13 264960 train loss: 0.0001957 valid loss: 0.0009673 P@1: 0.91549 P@3: 0.77278 P@5: 0.64148 N@3: 0.85554 N@5: 0.81561 early stop: 3\n","\u001b[32m[I 210618 08:21:45 models:110]\u001b[39m 13 290560 train loss: 0.0001962 valid loss: 0.0009685 P@1: 0.91554 P@3: 0.77265 P@5: 0.64152 N@3: 0.85546 N@5: 0.81563 early stop: 4\n","\u001b[32m[I 210618 08:25:02 models:110]\u001b[39m 13 316160 train loss: 0.0002003 valid loss: 0.0009696 P@1: 0.91549 P@3: 0.77263 P@5: 0.64155 N@3: 0.85543 N@5: 0.81564 early stop: 5\n","\u001b[32m[I 210618 08:28:20 models:110]\u001b[39m 13 341760 train loss: 0.0002014 valid loss: 0.0009708 P@1: 0.91540 P@3: 0.77261 P@5: 0.64152 N@3: 0.85539 N@5: 0.81559 early stop: 6\n","\u001b[32m[I 210618 08:31:36 models:110]\u001b[39m 13 367360 train loss: 0.0002045 valid loss: 0.0009719 P@1: 0.91545 P@3: 0.77261 P@5: 0.64152 N@3: 0.85541 N@5: 0.81561 early stop: 7\n","\u001b[32m[I 210618 08:34:55 models:110]\u001b[39m 13 392960 train loss: 0.0002085 valid loss: 0.0009730 P@1: 0.91547 P@3: 0.77264 P@5: 0.64151 N@3: 0.85544 N@5: 0.81560 early stop: 8\n","\u001b[32m[I 210618 08:38:13 models:110]\u001b[39m 13 418560 train loss: 0.0002088 valid loss: 0.0009742 P@1: 0.91549 P@3: 0.77263 P@5: 0.64156 N@3: 0.85542 N@5: 0.81562 early stop: 9\n","\u001b[32m[I 210618 08:41:29 models:110]\u001b[39m 13 444160 train loss: 0.0002106 valid loss: 0.0009752 P@1: 0.91560 P@3: 0.77262 P@5: 0.64151 N@3: 0.85544 N@5: 0.81560 early stop: 10\n","\u001b[32m[I 210618 08:44:46 models:110]\u001b[39m 13 469760 train loss: 0.0002152 valid loss: 0.0009762 P@1: 0.91545 P@3: 0.77264 P@5: 0.64157 N@3: 0.85542 N@5: 0.81560 early stop: 11\n","\u001b[32m[I 210618 08:48:03 models:110]\u001b[39m 13 495360 train loss: 0.0002146 valid loss: 0.0009773 P@1: 0.91550 P@3: 0.77263 P@5: 0.64151 N@3: 0.85543 N@5: 0.81557 early stop: 12\n","\u001b[32m[I 210618 08:51:19 models:110]\u001b[39m 13 520960 train loss: 0.0002186 valid loss: 0.0009782 P@1: 0.91547 P@3: 0.77263 P@5: 0.64152 N@3: 0.85543 N@5: 0.81558 early stop: 13\n","\u001b[32m[I 210618 08:54:36 models:110]\u001b[39m 13 546560 train loss: 0.0002188 valid loss: 0.0009792 P@1: 0.91547 P@3: 0.77260 P@5: 0.64153 N@3: 0.85541 N@5: 0.81559 early stop: 14\n","\u001b[32m[I 210618 08:57:53 models:110]\u001b[39m 14 7680 train loss: 0.0002018 valid loss: 0.0009803 P@1: 0.91543 P@3: 0.77264 P@5: 0.64156 N@3: 0.85543 N@5: 0.81560 early stop: 15\n","\u001b[32m[I 210618 09:01:10 models:110]\u001b[39m 14 33280 train loss: 0.0001563 valid loss: 0.0009815 P@1: 0.91545 P@3: 0.77264 P@5: 0.64159 N@3: 0.85543 N@5: 0.81562 early stop: 16\n","\u001b[32m[I 210618 09:04:25 models:110]\u001b[39m 14 58880 train loss: 0.0001598 valid loss: 0.0009827 P@1: 0.91549 P@3: 0.77274 P@5: 0.64163 N@3: 0.85552 N@5: 0.81566 early stop: 17\n","\u001b[32m[I 210618 09:07:40 models:110]\u001b[39m 14 84480 train loss: 0.0001618 valid loss: 0.0009839 P@1: 0.91547 P@3: 0.77270 P@5: 0.64155 N@3: 0.85548 N@5: 0.81560 early stop: 18\n","\u001b[32m[I 210618 09:10:58 models:110]\u001b[39m 14 110080 train loss: 0.0001652 valid loss: 0.0009852 P@1: 0.91546 P@3: 0.77272 P@5: 0.64156 N@3: 0.85551 N@5: 0.81561 early stop: 19\n","\u001b[32m[I 210618 09:14:14 models:110]\u001b[39m 14 135680 train loss: 0.0001675 valid loss: 0.0009864 P@1: 0.91540 P@3: 0.77278 P@5: 0.64159 N@3: 0.85554 N@5: 0.81562 early stop: 20\n","\u001b[32m[I 210618 09:17:30 models:110]\u001b[39m 14 161280 train loss: 0.0001730 valid loss: 0.0009876 P@1: 0.91535 P@3: 0.77278 P@5: 0.64153 N@3: 0.85552 N@5: 0.81558 early stop: 21\n","\u001b[32m[I 210618 09:20:45 models:110]\u001b[39m 14 186880 train loss: 0.0001729 valid loss: 0.0009888 P@1: 0.91542 P@3: 0.77275 P@5: 0.64156 N@3: 0.85551 N@5: 0.81560 early stop: 22\n","\u001b[32m[I 210618 09:24:01 models:110]\u001b[39m 14 212480 train loss: 0.0001759 valid loss: 0.0009900 P@1: 0.91543 P@3: 0.77275 P@5: 0.64152 N@3: 0.85549 N@5: 0.81556 early stop: 23\n","\u001b[32m[I 210618 09:27:18 models:110]\u001b[39m 14 238080 train loss: 0.0001783 valid loss: 0.0009912 P@1: 0.91547 P@3: 0.77277 P@5: 0.64155 N@3: 0.85552 N@5: 0.81558 early stop: 24\n","\u001b[32m[I 210618 09:30:34 models:110]\u001b[39m 14 263680 train loss: 0.0001798 valid loss: 0.0009923 P@1: 0.91545 P@3: 0.77273 P@5: 0.64153 N@3: 0.85550 N@5: 0.81557 early stop: 25\n","\u001b[32m[I 210618 09:33:52 models:110]\u001b[39m 14 289280 train loss: 0.0001833 valid loss: 0.0009934 P@1: 0.91543 P@3: 0.77274 P@5: 0.64155 N@3: 0.85550 N@5: 0.81558 early stop: 26\n","\u001b[32m[I 210618 09:37:10 models:110]\u001b[39m 14 314880 train loss: 0.0001864 valid loss: 0.0009946 P@1: 0.91543 P@3: 0.77271 P@5: 0.64150 N@3: 0.85547 N@5: 0.81554 early stop: 27\n","\u001b[32m[I 210618 09:40:28 models:110]\u001b[39m 14 340480 train loss: 0.0001847 valid loss: 0.0009957 P@1: 0.91539 P@3: 0.77269 P@5: 0.64153 N@3: 0.85543 N@5: 0.81554 early stop: 28\n","\u001b[32m[I 210618 09:43:44 models:110]\u001b[39m 14 366080 train loss: 0.0001861 valid loss: 0.0009968 P@1: 0.91542 P@3: 0.77264 P@5: 0.64157 N@3: 0.85541 N@5: 0.81557 early stop: 29\n","\u001b[32m[I 210618 09:47:00 models:110]\u001b[39m 14 391680 train loss: 0.0001915 valid loss: 0.0009979 P@1: 0.91537 P@3: 0.77261 P@5: 0.64155 N@3: 0.85537 N@5: 0.81553 early stop: 30\n","\u001b[32m[I 210618 09:50:17 models:110]\u001b[39m 14 417280 train loss: 0.0001923 valid loss: 0.0009991 P@1: 0.91527 P@3: 0.77263 P@5: 0.64152 N@3: 0.85536 N@5: 0.81548 early stop: 31\n","\u001b[32m[I 210618 09:53:35 models:110]\u001b[39m 14 442880 train loss: 0.0001932 valid loss: 0.0010001 P@1: 0.91530 P@3: 0.77255 P@5: 0.64153 N@3: 0.85531 N@5: 0.81549 early stop: 32\n","\u001b[32m[I 210618 09:56:51 models:110]\u001b[39m 14 468480 train loss: 0.0001938 valid loss: 0.0010012 P@1: 0.91527 P@3: 0.77250 P@5: 0.64154 N@3: 0.85525 N@5: 0.81548 early stop: 33\n","\u001b[32m[I 210618 10:00:07 models:110]\u001b[39m 14 494080 train loss: 0.0001954 valid loss: 0.0010022 P@1: 0.91527 P@3: 0.77252 P@5: 0.64154 N@3: 0.85526 N@5: 0.81548 early stop: 34\n","\u001b[32m[I 210618 10:03:23 models:110]\u001b[39m 14 519680 train loss: 0.0001962 valid loss: 0.0010032 P@1: 0.91530 P@3: 0.77251 P@5: 0.64153 N@3: 0.85526 N@5: 0.81548 early stop: 35\n","\u001b[32m[I 210618 10:06:39 models:110]\u001b[39m 14 545280 train loss: 0.0002007 valid loss: 0.0010042 P@1: 0.91522 P@3: 0.77254 P@5: 0.64155 N@3: 0.85528 N@5: 0.81548 early stop: 36\n","\u001b[32m[I 210618 10:08:46 main:76]\u001b[39m Finish Training\n","\u001b[32m[I 210618 10:08:57 main:32]\u001b[39m Model Name: MATCH\n","\u001b[32m[I 210618 10:08:57 main:79]\u001b[39m Loading Test Set\n","\u001b[32m[I 210618 10:09:01 main:83]\u001b[39m Size of Test Set: 70533\n","\u001b[32m[I 210618 10:09:01 main:85]\u001b[39m Predicting\n","\u001b[32m[I 210618 10:09:30 main:91]\u001b[39m Finish Predicting\n","Precision@1,3,5: 0.9148909021309174 0.7706416381929971 0.6392610551089561\n","nDCG@1,3,5: 0.9148909021309174 0.8551977454602886 0.8154306415429102\n"],"name":"stdout"}]}]}